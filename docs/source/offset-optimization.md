# Оптимизация на основе офсетов (Offset Optimization)

## Введение

Оптимизация на основе офсетов (offset optimization) — это функция, которая значительно повышает производительность инкрементальной обработки данных путем отслеживания временной метки последней обработки (offset) для каждой входной таблицы трансформации. Это позволяет Datapipe пропускать уже обработанные записи без полного сканирования таблицы метаданных трансформации.

## Краткая концепция

### Традиционный подход (v1)

Без оптимизации Datapipe использует FULL OUTER JOIN между входными таблицами и таблицей метаданных трансформации для поиска измененных записей. Этот подход корректен, но требует полного сканирования метаданных на каждом запуске, что замедляет обработку по мере роста объема обработанных данных.

**Сложность:** O(N), где N — размер таблицы метаданных

### Оптимизированный подход (v2)

С включенной оптимизацией Datapipe:
1. **Отслеживает офсеты** — для каждой входной таблицы трансформации хранится максимальная обработанная временная метка `update_ts`
2. **Фильтрует данные рано** — применяет фильтр `WHERE update_ts >= offset` на уровне входных таблиц, используя индекс
3. **Минимизирует сканирование** — обрабатывает только записи, измененные с момента последнего запуска
4. **Атомарно фиксирует офсеты** — обновляет офсеты только после успешного завершения всего run_full

**Сложность:** O(M), где M — количество записей, измененных с последнего запуска

## Основные возможности (Features)

### 1. Хранение и управление офсетами

**TransformInputOffsetTable** — таблица для хранения офсетов с API для:
- Получения офсетов для трансформации
- Атомарного обновления одного или нескольких офсетов
- Инициализации офсетов из существующих метаданных
- Сброса офсетов для полной переобработки

[Подробнее →](./offset-optimization-storage.md)

### 2. Оптимизированные SQL-запросы (v1 vs v2)

Два алгоритма построения запросов на поиск измененных записей:
- **v1 (FULL OUTER JOIN)** — традиционный подход без офсетов
- **v2 (Offset-based)** — оптимизированный подход с ранней фильтрацией по офсетам

[Подробнее →](./offset-optimization-sql-queries.md)

### 3. Reverse Join для референсных таблиц

При изменении записей в референсной таблице (например, справочник пользователей) Datapipe автоматически находит все зависимые записи в основной таблице через **reverse join** с использованием `join_keys`.

**Пример:** При обновлении `profiles.name` находятся все `posts` этого пользователя через `posts.profile_id = profiles.id`.

[Подробнее →](./offset-optimization-reverse-join.md)

### 4. Filtered Join — оптимизация чтения референсных таблиц

Вместо чтения всей референсной таблицы, Datapipe извлекает только те записи, которые реально нужны для обработки текущего батча. Это достигается через фильтрацию по уникальным значениям внешних ключей из индекса измененных записей.

**Пример:** Если обрабатываются посты 10 пользователей, из таблицы `profiles` читаются только профили этих 10 пользователей, а не все миллионы.

[Подробнее →](./offset-optimization-filtered-join.md)

### 5. Стратегия фиксации офсетов

Офсеты фиксируются **атомарно в конце run_full** после успешной обработки всех батчей. Это гарантирует:
- **Отсутствие потери данных** — при сбое в середине обработки офсет не изменяется, данные переобработаются
- **Изоляцию от run_changelist** — инкрементальные запуски не меняют глобальные офсеты
- **Корректное восстановление** — после перезапуска обработка продолжается с последнего гарантированно завершенного run_full

**Планы развития:** В планах вернуть коммит офсетов после каждого батча, чтобы избежать ситуации, когда при сбое во время обработки большой таблицы приходится начинать с самого начала. При побатчевом коммите офсет будет сохраняться после каждого успешно обработанного батча, что позволит продолжить обработку с последнего завершенного батча вместо полной переобработки.

[Подробнее →](./offset-optimization-commit-strategy.md)

### 6. Инициализация офсетов

Функция **initialize_offsets_from_transform_meta()** позволяет включить оптимизацию на существующих трансформациях без потери данных:
1. Находит MIN(process_ts) из успешно обработанных записей
2. Для каждой входной таблицы находит MAX(update_ts) где update_ts <= min_process_ts
3. Устанавливает это значение как начальный офсет

[Подробнее →](./offset-optimization-initialization.md)

## Как включить оптимизацию

### В определении трансформации

```python
from datapipe.step.batch_transform import BatchTransformStep
from datapipe.compute import ComputeInput

step = BatchTransformStep(
    ds=ds,
    name="process_posts",
    func=transform_function,
    input_dts=[
        # Основная таблица (без join_keys)
        ComputeInput(dt=posts_table, join_type="full"),

        # Референсная таблица с reverse join
        ComputeInput(
            dt=profiles_table,
            join_type="inner",
            join_keys={"user_id": "id"}  # posts.user_id = profiles.id
        ),
    ],
    output_dts=[output_table],
    transform_keys=["post_id"],

    # Включение offset-оптимизации
    use_offset_optimization=True
)
```

### В runtime через RunConfig

```python
from datapipe.run_config import RunConfig

run_config = RunConfig(
    labels={"use_offset_optimization": True}
)

step.run_full(ds, run_config=run_config)
```

## Когда использовать

### Рекомендуется использовать

- ✅ **Большие таблицы метаданных** — трансформации с большим количеством обработанных записей (> 100k)
- ✅ **Инкрементальные обновления** — малая доля данных изменяется на каждом запуске (< 10%)
- ✅ **Индекс на update_ts** — входные таблицы имеют индекс на поле update_ts
- ✅ **Референсные таблицы** — используются справочники с join_keys
- ✅ **Production окружение** — стабильные пайплайны с регулярными запусками

### Не рекомендуется использовать

- ❌ **Полная переобработка** — если обрабатываются все данные на каждом запуске
- ❌ **Малый объем метаданных** — если таблица метаданных небольшая (< 10k записей)
- ❌ **Высокая доля изменений** — если большинство записей обновляется на каждом запуске (> 50%)
- ❌ **Разработка/отладка** — на этапе разработки удобнее использовать v1 для простоты

## Архитектура и поток данных

```
┌─────────────────────────────────────────────────────────────┐
│                        DataStore                            │
│  ┌──────────────────────────────────────────────────────┐   │
│  │ offset_table: TransformInputOffsetTable              │   │
│  │  - get_offset(transformation_id, table_name)         │   │
│  │  - update_offsets_bulk(offsets)                      │   │
│  └──────────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────────┘
                            ↑
                            │ используется в run_full()
                            │
┌─────────────────────────────────────────────────────────────┐
│              BaseBatchTransformStep                         │
│                                                             │
│  1. build_changed_idx_sql() → v2 с офсетами                 │
│  2. get_batch_input_dfs() → filtered join                   │
│  3. store_batch_result() → накопление офсетов в ChangeList  │
│  4. run_full() → фиксация офсетов через                     │
│     offset_table.update_offsets_bulk()                      │
└─────────────────────────────────────────────────────────────┘
```

## Критически важные детали реализации

1. **Инклюзивное неравенство** — используется `>=` а не `>` для избежания потери граничных записей
2. **Проверка process_ts** — даже с офсетом проверяется `process_ts > update_ts` для предотвращения зацикливания
3. **Reverse join для референсов** — автоматическое построение обратного join при наличии join_keys
4. **Атомарная фиксация офсетов** — офсеты фиксируются только после успешного run_full
5. **Записи с ошибками всегда включены** — записи с `is_success != True` включаются вне зависимости от офсета
6. **NULL update_ts для ошибок** — записи с ошибками маркируются NULL update_ts для отличия от измененных записей
7. **Сортировка по update_ts** — хронологический порядок критичен для корректности офсетов

## Дополнительные материалы

**Детальное описание фич:**
- [Хранение и управление офсетами](./offset-optimization-storage.md)
- [Оптимизированные SQL-запросы](./offset-optimization-sql-queries.md)
- [Reverse Join](./offset-optimization-reverse-join.md)
- [Filtered Join](./offset-optimization-filtered-join.md)
- [Стратегия фиксации офсетов](./offset-optimization-commit-strategy.md)
- [Инициализация офсетов](./offset-optimization-initialization.md)
- [Метрики и мониторинг](./offset-optimization-monitoring.md)

## Тестирование

Offset-оптимизация покрыта комплексным набором тестов:
- `tests/test_offset_table.py` — операции с таблицей офсетов
- `tests/test_offset_auto_update.py` — автоматическое обновление офсетов
- `tests/test_offset_joinspec.py` — reverse join с join_keys
- `tests/test_multi_table_filtered_join.py` — filtered join
- `tests/test_batch_transform_with_offset_optimization.py` — интеграционные тесты
- `tests/offset_edge_cases/` — граничные случаи и edge cases (13+ тестов)

Нагрузочное тестирование: https://github.com/epoch8/datapipe-perf

## Мониторинг и метрики

Offset-оптимизация предоставляет метрики для мониторинга через Prometheus. Таблица офсетов поддерживает метод `get_statistics()`, который возвращает статистику по офсетам:

```python
# Получить статистику по всем офсетам
stats = ds.offset_table.get_statistics()

# Получить статистику для конкретной трансформации
stats = ds.offset_table.get_statistics(transformation_id="process_posts")
```

**Доступные метрики:**
- `transformation_id` — ID трансформации
- `input_table_name` — имя входной таблицы
- `update_ts_offset` — текущее значение офсета (timestamp)
- `offset_age_seconds` — возраст офсета в секундах (сколько времени прошло с момента last processed update_ts)

**Использование для мониторинга:**

Метрика `offset_age_seconds` особенно полезна для мониторинга:
- **Растущий offset_age** — индикатор того, что обработка отстает от поступления данных
- **Стабильный offset_age** — нормальная работа с регулярными запусками
- **Большой offset_age** — возможная проблема (трансформация долго не запускалась или упала)

Эти метрики можно экспортировать в Prometheus для визуализации в Grafana и настройки алертов.

## История и текущий статус

Offset-оптимизация прошла первое тестирование в production окружении и показала значительное улучшение производительности для трансформаций с большими объемами обработанных данных. Функция стабильна и готова для использования в production.

**Ветка разработки:** `Looky-7769/offsets`
