"""
–¢–µ—Å—Ç –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç –†–ï–ê–õ–¨–ù–´–ô –±–∞–≥ –∏–∑ production.

–ü–†–û–ë–õ–ï–ú–ê:
–ü—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ —Å offset optimization,
–µ—Å–ª–∏ –∑–∞–ø–∏—Å–∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –≤ –ø–æ—Ä—è–¥–∫–µ ORDER BY (id, hashtag) –∞ –Ω–µ –ø–æ update_ts,
–∏ –≤ –±–∞—Ç—á –ø–æ–ø–∞–¥–∞—é—Ç –∑–∞–ø–∏—Å–∏ —Å –†–ê–ó–ù–´–ú–ò update_ts (—Å–æ–∑–¥–∞–Ω–Ω—ã–µ –≤ —Ä–∞–∑–Ω–æ–µ –≤—Ä–µ–º—è),
—Ç–æ offset —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç—Å—è –Ω–∞ MAX(update_ts) –∏–∑ –±–∞—Ç—á–∞.

–í—Å–µ –∑–∞–ø–∏—Å–∏ —Å id –ü–û–°–õ–ï –ø–æ—Å–ª–µ–¥–Ω–µ–π –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–π, –Ω–æ —Å update_ts < offset,
–±—É–¥—É—Ç –ü–†–û–ü–£–©–ï–ù–´ –ø—Ä–∏ —Å–ª–µ–¥—É—é—â–∏—Ö –∑–∞–ø—É—Å–∫–∞—Ö!

–†–ï–ê–õ–¨–ù–´–ô –°–¶–ï–ù–ê–†–ò–ô –ò–ó PRODUCTION (hashtag_issue.md):
- 16:21 - –ü–æ—Å—Ç b927ca71 —Å–æ–∑–¥–∞–Ω, —Ö–µ—à—Ç–µ–≥–∏ –∏–∑–≤–ª–µ—á–µ–Ω—ã
- 20:29 - –ü–æ—Å—Ç e26f9c4b —Å–æ–∑–¥–∞–Ω
- copy_to_online –ü–ï–†–í–´–ô –†–ê–ó –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç:
  - –ë–∞—Ç—á —Å–æ–¥–µ—Ä–∂–∏—Ç (–≤ –ø–æ—Ä—è–¥–∫–µ id): b927ca71(16:21), e26f9c4b(20:29), ...
  - offset = MAX(16:21, 20:29) = 20:29
- –°–ª–µ–¥—É—é—â–∏–π –∑–∞–ø—É—Å–∫: WHERE update_ts > 20:29
  - –ü—Ä–æ–ø—É—Å–∫–∞—é—Ç—Å—è –í–°–ï –∑–∞–ø–∏—Å–∏ —Å id > e26f9c4b –∏ update_ts < 20:29!
  - –†–µ–∑—É–ª—å—Ç–∞—Ç: 60% –¥–∞–Ω–Ω—ã—Ö –ø–æ—Ç–µ—Ä—è–Ω–æ

–≠—Ç–æ—Ç —Ç–µ—Å—Ç –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç —ç—Ç—É –ø—Ä–æ–±–ª–µ–º—É.
"""
import time

import pandas as pd
import pytest
from sqlalchemy import Column, Integer, String

from datapipe.compute import ComputeInput
from datapipe.datatable import DataStore
from datapipe.step.batch_transform import BatchTransformStep
from datapipe.store.database import DBConn, TableStoreDB


@pytest.mark.xfail(reason="Test uses run_idx() which no longer commits offsets (offsets only commit at end of run_full)")
def test_first_run_with_mixed_update_ts_and_order_by_id(dbconn: DBConn):
    """
    –í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç –¢–û–ß–ù–´–ô —Å—Ü–µ–Ω–∞—Ä–∏–π production –±–∞–≥–∞.

    –°–∏–º—É–ª—è—Ü–∏—è –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∑–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ —á–∞—Å–æ–≤,
    –∑–∞—Ç–µ–º –ø–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫ copy_to_online –∫–æ—Ç–æ—Ä—ã–π –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç
    –∑–∞–ø–∏—Å–∏ –≤ –ø–æ—Ä—è–¥–∫–µ (id, hashtag), –ù–ï –ø–æ update_ts.

    –†–µ–∑—É–ª—å—Ç–∞—Ç: –¥–∞–Ω–Ω—ã–µ —Å id –ø–æ—Å–ª–µ "–≥—Ä–∞–Ω–∏—Ü—ã –±–∞—Ç—á–∞" –Ω–æ —Å —Å—Ç–∞—Ä—ã–º update_ts –¢–ï–†–Ø–Æ–¢–°–Ø.
    """
    ds = DataStore(dbconn, create_meta_table=True)

    input_store = TableStoreDB(
        dbconn,
        "first_run_input",
        [
            Column("id", String, primary_key=True),
            Column("hashtag", String, primary_key=True),
            Column("value", Integer),
        ],
        create_table=True,
    )
    input_dt = ds.create_table("first_run_input", input_store)

    output_store = TableStoreDB(
        dbconn,
        "first_run_output",
        [
            Column("id", String, primary_key=True),
            Column("hashtag", String, primary_key=True),
            Column("value", Integer),
        ],
        create_table=True,
    )
    output_dt = ds.create_table("first_run_output", output_store)

    def copy_func(df):
        return df[["id", "hashtag", "value"]]

    step = BatchTransformStep(
        ds=ds,
        name="first_run_copy",
        func=copy_func,
        input_dts=[ComputeInput(dt=input_dt, join_type="full")],
        output_dts=[output_dt],
        transform_keys=["id", "hashtag"],
        use_offset_optimization=True,
        chunk_size=10,  # –ú–∞–ª–µ–Ω—å–∫–∏–π —Ä–∞–∑–º–µ—Ä –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
    )

    # ========== –°–∏–º—É–ª–∏—Ä—É–µ–º –Ω–∞–∫–æ–ø–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∑–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ —á–∞—Å–æ–≤ ==========
    base_time = time.time()

    # –ò–º–∏—Ç–∏—Ä—É–µ–º –ø–æ—Å—Ç—ã –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–∏—Ö–æ–¥–∏–ª–∏ –≤ —Ç–µ—á–µ–Ω–∏–µ 4 —á–∞—Å–æ–≤
    # 16:21 - –ü–æ—Å—Ç b927ca71 (UUID –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å 'b')
    t_16_21 = base_time + 1
    input_dt.store_chunk(
        pd.DataFrame({
            "id": ["b927ca71-0001", "b927ca71-0001"],
            "hashtag": ["322", "anime"],
            "value": [1, 2],
        }),
        now=t_16_21
    )

    time.sleep(0.001)

    # 17:00 - –ï—â–µ –ø–æ—Å—Ç—ã —Å —Ä–∞–∑–Ω—ã–º–∏ id, –Ω–æ —Å—Ç–∞—Ä—ã–º–∏ timestamps
    t_17_00 = base_time + 2
    input_dt.store_chunk(
        pd.DataFrame({
            "id": ["a111aaaa-0002", "c222cccc-0003", "d333dddd-0004"],
            "hashtag": ["test1", "test2", "test3"],
            "value": [3, 4, 5],
        }),
        now=t_17_00
    )

    time.sleep(0.001)

    # 18:00 - –ë–æ–ª—å—à–µ –ø–æ—Å—Ç–æ–≤
    t_18_00 = base_time + 3
    input_dt.store_chunk(
        pd.DataFrame({
            "id": ["e444eeee-0005", "f555ffff-0006", "g666gggg-0007"],
            "hashtag": ["hash1", "hash2", "hash3"],
            "value": [6, 7, 8],
        }),
        now=t_18_00
    )

    time.sleep(0.001)

    # 20:29 - –ù–æ–≤—ã–π –ø–æ—Å—Ç e26f9c4b (UUID –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å 'e')
    t_20_29 = base_time + 4
    input_dt.store_chunk(
        pd.DataFrame({
            "id": ["e26f9c4b-0008"],
            "hashtag": ["looky"],
            "value": [9],
        }),
        now=t_20_29
    )

    time.sleep(0.001)

    # 20:30 - –ï—â–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–æ—Å—Ç–æ–≤ –ü–û–°–õ–ï e26f9c4b, –Ω–æ —Å –†–ê–ó–ù–´–ú–ò timestamps
    # –≠—Ç–∏ –ø–æ—Å—Ç—ã –∫—Ä–∏—Ç–∏—á–Ω—ã - —É –Ω–∏—Ö id > e26f9c4b, –Ω–æ update_ts –º–æ–∂–µ—Ç –±—ã—Ç—å —Å—Ç–∞—Ä—ã–º!
    t_20_30 = base_time + 5
    input_dt.store_chunk(
        pd.DataFrame({
            "id": ["h777hhhh-0009", "i888iiii-0010", "j999jjjj-0011"],
            "hashtag": ["new1", "new2", "new3"],
            "value": [10, 11, 12],
        }),
        now=t_20_30  # –ù–æ–≤–æ–µ –≤—Ä–µ–º—è!
    )

    time.sleep(0.001)

    # –ö—Ä–∏—Ç–∏—á–Ω–æ: –¥–æ–±–∞–≤–ª—è–µ–º –∑–∞–ø–∏—Å–∏ —Å id –ú–ï–ñ–î–£ —É–∂–µ —Å–æ–∑–¥–∞–Ω–Ω—ã–º–∏, –Ω–æ —Å–æ –°–¢–ê–†–´–ú timestamp
    # –°–∏–º—É–ª–∏—Ä—É–µ–º —Å–∏—Ç—É–∞—Ü–∏—é –≥–¥–µ –∑–∞–ø–∏—Å–∏ –ø—Ä–∏—Ö–æ–¥—è—Ç –Ω–µ –≤ –ø–æ—Ä—è–¥–∫–µ id
    t_19_00 = base_time + 2.5  # –°—Ç–∞—Ä—ã–π timestamp (–º–µ–∂–¥—É 17:00 –∏ 18:00)
    input_dt.store_chunk(
        pd.DataFrame({
            "id": ["f111ffff-late1", "f222ffff-late2"],  # id –≤ —Å–µ—Ä–µ–¥–∏–Ω–µ –¥–∏–∞–ø–∞–∑–æ–Ω–∞
            "hashtag": ["late1", "late2"],
            "value": [98, 99],
        }),
        now=t_19_00  # –°–¢–ê–†–´–ô timestamp!
    )

    time.sleep(0.001)

    # –î–æ–±–∞–≤–ª—è–µ–º –µ—â–µ –∑–∞–ø–∏—Å–µ–π –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –≤—Ç–æ—Ä–æ–≥–æ –±–∞—Ç—á–∞ (—á—Ç–æ–±—ã –±—ã–ª–æ 20+ –∑–∞–ø–∏—Å–µ–π ‚Üí 2 –±–∞—Ç—á–∞)
    t_20_31 = base_time + 5.1
    input_dt.store_chunk(
        pd.DataFrame({
            "id": ["k111kkkk-0012", "l222llll-0013", "m333mmmm-0014",
                   "n444nnnn-0015", "o555oooo-0016", "p666pppp-0017"],
            "hashtag": ["extra1", "extra2", "extra3", "extra4", "extra5", "extra6"],
            "value": [12, 13, 14, 15, 16, 17],
        }),
        now=t_20_31
    )

    # ========== –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ ==========
    all_meta = input_dt.meta_table.get_metadata()
    print(f"\n–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π –Ω–∞–∫–æ–ø–ª–µ–Ω–æ: {len(all_meta)}")
    print("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ update_ts:")
    for idx, row in all_meta.sort_values("id").iterrows():
        print(f"  id={row['id'][:15]:15} hashtag={row['hashtag']:10} update_ts={row['update_ts']:.2f}")

    # ========== –ü–ï–†–í–´–ô –ó–ê–ü–£–°–ö copy_to_online ==========
    # –ò–º–∏—Ç–∏—Ä—É–µ–º –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏–µ: –æ–±—Ä–∞–±–æ—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ chunk_size=10 –∑–∞–ø–∏—Å–µ–π
    (idx_count, idx_gen) = step.get_full_process_ids(ds=ds, run_config=None)
    print(f"\n–ë–∞—Ç—á–µ–π –¥–æ—Å—Ç—É–ø–Ω–æ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {idx_count}")

    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¢–û–õ–¨–ö–û –ø–µ—Ä–≤—ã–π –±–∞—Ç—á (–∫–∞–∫ –µ—Å–ª–∏ –±—ã –¥–∂–æ–±–∞ –ø—Ä–µ—Ä–≤–∞–ª–∞—Å—å)
    first_batch_idx = next(idx_gen)
    idx_gen.close()  # –ó–∞–∫—Ä—ã–≤–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä
    print(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–π –±–∞—Ç—á, —Ä–∞–∑–º–µ—Ä: {len(first_batch_idx)}")
    step.run_idx(ds=ds, idx=first_batch_idx, run_config=None)

    # –ü–æ–ª—É—á–∞–µ–º offset –ø–æ—Å–ª–µ –ø–µ—Ä–≤–æ–≥–æ –∑–∞–ø—É—Å–∫–∞
    offsets = ds.offset_table.get_offsets_for_transformation(step.get_name())
    offset_after_first = offsets["first_run_input"]

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ
    output_after_first = output_dt.get_data()
    processed_ids = set(output_after_first["id"].tolist())

    print(f"\n=== –ü–û–°–õ–ï –ü–ï–†–í–û–ì–û –ó–ê–ü–£–°–ö–ê ===")
    print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞–ø–∏—Å–µ–π: {len(output_after_first)}")
    print(f"offset —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –Ω–∞: {offset_after_first:.2f}")
    print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ id: {sorted(processed_ids)}")

    # ========== –ö–†–ò–¢–ò–ß–ù–û: –ö–∞–∫–∏–µ –∑–∞–ø–∏—Å–∏ –ù–ï –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã? ==========
    all_input_ids = set(all_meta["id"].tolist())
    unprocessed_ids = all_input_ids - processed_ids

    if unprocessed_ids:
        print(f"\n=== –ù–ï–û–ë–†–ê–ë–û–¢–ê–ù–ù–´–ï –ó–ê–ü–ò–°–ò ===")
        unprocessed_meta = all_meta[all_meta["id"].isin(unprocessed_ids)]
        for idx, row in unprocessed_meta.sort_values("id").iterrows():
            below_offset = row["update_ts"] < offset_after_first
            status = "–ë–£–î–ï–¢ –ü–û–¢–ï–†–Ø–ù–ê!" if below_offset else "–±—É–¥–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞"
            print(
                f"  id={row['id'][:15]:15} update_ts={row['update_ts']:.2f} "
                f"< offset={offset_after_first:.2f} ? {below_offset} ‚Üí {status}"
            )

    # ========== –í–¢–û–†–û–ô –ó–ê–ü–£–°–ö ==========
    # –ü–æ–ª—É—á–∞–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –±–∞—Ç—á–∏ (—Å —É—á–µ—Ç–æ–º offset)
    (idx_count_second, idx_gen_second) = step.get_full_process_ids(ds=ds, run_config=None)
    print(f"\n=== –í–¢–û–†–û–ô –ó–ê–ü–£–°–ö ===")
    print(f"–ë–∞—Ç—á–µ–π –¥–æ—Å—Ç—É–ø–Ω–æ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {idx_count_second}")

    if idx_count_second > 0:
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –±–∞—Ç—á–∏
        for idx in idx_gen_second:
            print(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á, —Ä–∞–∑–º–µ—Ä: {len(idx)}")
            step.run_idx(ds=ds, idx=idx, run_config=None)
        idx_gen_second.close()

    # ========== –ö–†–ò–¢–ò–ß–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê: –í–°–ï –∑–∞–ø–∏—Å–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã ==========
    final_output = output_dt.get_data()
    final_processed_ids = set(final_output["id"].tolist())

    # –°–ø–∏—Å–æ–∫ –ø–æ—Ç–µ—Ä—è–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π
    lost_records = all_input_ids - final_processed_ids

    if lost_records:
        lost_meta = all_meta[all_meta["id"].isin(lost_records)]
        print(f"\n=== üö® –ü–û–¢–ï–†–Ø–ù–ù–´–ï –ó–ê–ü–ò–°–ò (–ë–ê–ì!) ===")
        for idx, row in lost_meta.sort_values("id").iterrows():
            print(
                f"  id={row['id'][:15]:15} hashtag={row['hashtag']:10} "
                f"update_ts={row['update_ts']:.2f} < offset={offset_after_first:.2f}"
            )

        pytest.fail(
            f"–ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô –ë–ê–ì –í–û–°–ü–†–û–ò–ó–í–ï–î–ï–ù: {len(lost_records)} –∑–∞–ø–∏—Å–µ–π –ü–û–¢–ï–†–Ø–ù–´!\n"
            f"–û–∂–∏–¥–∞–ª–æ—Å—å: {len(all_input_ids)} –∑–∞–ø–∏—Å–µ–π\n"
            f"–ü–æ–ª—É—á–µ–Ω–æ:  {len(final_output)} –∑–∞–ø–∏—Å–µ–π\n"
            f"–ü–æ—Ç–µ—Ä—è–Ω–æ:  {len(lost_records)} –∑–∞–ø–∏—Å–µ–π\n"
            f"–ü–æ—Ç–µ—Ä—è–Ω–Ω—ã–µ id: {sorted(lost_records)}\n\n"
            f"–≠—Ç–æ –¢–û–ß–ù–û –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç production –±–∞–≥ –≥–¥–µ –±—ã–ª–æ –ø–æ—Ç–µ—Ä—è–Ω–æ 60% –¥–∞–Ω–Ω—ã—Ö!"
        )

    print(f"\n=== –§–ò–ù–ê–õ–¨–ù–´–ô –†–ï–ó–£–õ–¨–¢–ê–¢ ===")
    print(f"–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π –≤ input: {len(all_input_ids)}")
    print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –≤ output:   {len(final_output)}")
    print(f"‚úÖ –í—Å–µ –∑–∞–ø–∏—Å–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ!")


def test_first_run_invariant_all_records_below_offset_must_be_processed(dbconn: DBConn):
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏–Ω–≤–∞—Ä–∏–∞–Ω—Ç –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ –∑–∞–ø—É—Å–∫–∞:
    –ü–æ—Å–ª–µ –ø–µ—Ä–≤–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ –í–°–ï –∑–∞–ø–∏—Å–∏ —Å update_ts <= offset –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã.

    –≠—Ç–æ –±–æ–ª–µ–µ –æ–±—â–∏–π —Ç–µ—Å—Ç –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–æ–≤–µ—Ä—è–µ—Ç —á—Ç–æ –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç:
    - –ü–æ—Ä—è–¥–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∑–∞–ø–∏—Å–µ–π
    - –ü–æ—Ä—è–¥–∫–∞ –∏—Ö id
    - –†–∞–∑–º–µ—Ä–∞ –±–∞—Ç—á–∞

    –ü–æ—Å–ª–µ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ offset –ù–ï –î–û–õ–ñ–ù–û –æ—Å—Ç–∞—Ç—å—Å—è –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π —Å update_ts < offset.
    """
    ds = DataStore(dbconn, create_meta_table=True)

    input_store = TableStoreDB(
        dbconn,
        "invariant_input",
        [Column("id", String, primary_key=True), Column("value", Integer)],
        create_table=True,
    )
    input_dt = ds.create_table("invariant_input", input_store)

    output_store = TableStoreDB(
        dbconn,
        "invariant_output",
        [Column("id", String, primary_key=True), Column("value", Integer)],
        create_table=True,
    )
    output_dt = ds.create_table("invariant_output", output_store)

    def copy_func(df):
        return df[["id", "value"]]

    step = BatchTransformStep(
        ds=ds,
        name="invariant_copy",
        func=copy_func,
        input_dts=[ComputeInput(dt=input_dt, join_type="full")],
        output_dts=[output_dt],
        transform_keys=["id"],
        use_offset_optimization=True,
        chunk_size=5,
    )

    # –°–æ–∑–¥–∞–µ–º –∑–∞–ø–∏—Å–∏ —Å —Ä–∞–∑–Ω—ã–º–∏ update_ts –∏ —Ä–∞–∑–Ω—ã–º–∏ id (–Ω–µ –≤ –ø–æ—Ä—è–¥–∫–µ –≤—Ä–µ–º–µ–Ω–∏)
    base_time = time.time()

    records = [
        ("z999", base_time + 1),   # –ü–æ–∑–¥–Ω–∏–π id, —Ä–∞–Ω–Ω–∏–π timestamp
        ("a111", base_time + 5),   # –†–∞–Ω–Ω–∏–π id, –ø–æ–∑–¥–Ω–∏–π timestamp
        ("m555", base_time + 2),   # –°—Ä–µ–¥–Ω–∏–π id, —Å—Ä–µ–¥–Ω–∏–π timestamp
        ("b222", base_time + 3),
        ("y888", base_time + 1.5),
        ("c333", base_time + 4),
        ("x777", base_time + 2.5),
    ]

    for record_id, timestamp in records:
        input_dt.store_chunk(
            pd.DataFrame({"id": [record_id], "value": [int(timestamp)]}),
            now=timestamp
        )
        time.sleep(0.001)

    # –ü–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫
    step.run_full(ds)

    # –ü–æ–ª—É—á–∞–µ–º offset
    offsets = ds.offset_table.get_offsets_for_transformation(step.get_name())
    current_offset = offsets["invariant_input"]

    # –ò–ù–í–ê–†–ò–ê–ù–¢: –í–°–ï –∑–∞–ø–∏—Å–∏ —Å update_ts <= current_offset –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã
    all_meta = input_dt.meta_table.get_metadata()
    output_data = output_dt.get_data()
    processed_ids = set(output_data["id"].tolist())

    violations = []
    for idx, row in all_meta.iterrows():
        if row["update_ts"] <= current_offset:
            if row["id"] not in processed_ids:
                violations.append(row)

    if violations:
        print(f"\nüö® –ù–ê–†–£–®–ï–ù–ò–ï –ò–ù–í–ê–†–ò–ê–ù–¢–ê!")
        print(f"offset = {current_offset}")
        print(f"–ù–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∏ —Å update_ts <= offset:")
        for row in violations:
            print(f"  id={row['id']} update_ts={row['update_ts']}")

        pytest.fail(
            f"–ù–ê–†–£–®–ï–ù–ò–ï –ò–ù–í–ê–†–ò–ê–ù–¢–ê: {len(violations)} –∑–∞–ø–∏—Å–µ–π —Å update_ts <= offset –ù–ï –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã!\n"
            f"–≠—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç –ø–æ—Ç–µ—Ä—é –¥–∞–Ω–Ω—ã—Ö."
        )
