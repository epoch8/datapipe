"""
–¢–µ—Å—Ç –¥–ª—è –≥–∏–ø–æ—Ç–µ–∑—ã 3: –†–∞—Å—Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è update_ts –∏ process_ts –≤ multi-step pipeline.

–ì–ò–ü–û–¢–ï–ó–ê 3 (–∏–∑ README.md):
"–î—Ä—É–≥–∞—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–±–Ω–æ–≤–ª—è–µ—Ç process_ts, –Ω–æ –ù–ï update_ts"

–°–¶–ï–ù–ê–†–ò–ô –ò–ó PRODUCTION:
1. Transform_extract_hashtags —Å–æ–∑–¥–∞–µ—Ç –∑–∞–ø–∏—Å–∏ –≤ hashtag_table (update_ts=16:21)
2. Transform_hashtag_stats –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç hashtag_table —Å–ø—É—Å—Ç—è 4 —á–∞—Å–∞ (20:04)
   - process_ts –≤ Transform_hashtag_stats.meta_table = 20:04
   - update_ts –≤ hashtag_table (input) –æ—Å—Ç–∞–µ—Ç—Å—è = 16:21
3. offset(Transform_hashtag_stats, hashtag_table) = 16:21 (MAX update_ts –∏–∑ input)
4. –í—Ä–µ–º–µ–Ω–Ω–æ–π —Ä–∞–∑—Ä—ã–≤: update_ts=16:21, process_ts=20:04

–í–û–ü–†–û–°:
–í–ª–∏—è–µ—Ç –ª–∏ —ç—Ç–∞ —Ä–∞—Å—Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –Ω–∞ offset optimization?
–ú–æ–∂–µ—Ç –ª–∏ —ç—Ç–æ –≤—ã–∑–≤–∞—Ç—å –ø–æ—Ç–µ—Ä—é –¥–∞–Ω–Ω—ã—Ö?

–ê–†–•–ò–¢–ï–ö–¢–£–†–ê:
- –£ –∫–∞–∂–¥–æ–π —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –°–í–û–Ø TransformMetaTable —Å –°–í–û–ò–ú process_ts
- Transform_A.meta_table —Ö—Ä–∞–Ω–∏—Ç process_ts –¥–ª—è Transform_A
- Transform_B.meta_table —Ö—Ä–∞–Ω–∏—Ç process_ts –¥–ª—è Transform_B
- –û–Ω–∏ –Ω–µ –ø–µ—Ä–µ—Å–µ–∫–∞—é—Ç—Å—è!

–û–ñ–ò–î–ê–ù–ò–ï:
–†–∞—Å—Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –ù–ï –¥–æ–ª–∂–Ω–∞ –≤–ª–∏—è—Ç—å –Ω–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å offset optimization,
—Ç–∞–∫ –∫–∞–∫ –∫–∞–∂–¥–∞—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è —Ä–∞–±–æ—Ç–∞–µ—Ç —Å–æ —Å–≤–æ–∏–º process_ts.
"""
import time

import pandas as pd
import pytest
import sqlalchemy as sa
from sqlalchemy import Column, Integer, String

from datapipe.compute import ComputeInput
from datapipe.datatable import DataStore
from datapipe.step.batch_transform import BatchTransformStep
from datapipe.store.database import DBConn, TableStoreDB


def test_hypothesis_3_multi_step_pipeline_update_ts_vs_process_ts_desync(dbconn: DBConn):
    """
    –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥–∏–ø–æ—Ç–µ–∑—ã 3: –†–∞—Å—Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è update_ts –∏ process_ts –≤ multi-step pipeline.

    Pipeline:
    source_table ‚Üí Transform_A ‚Üí intermediate_table ‚Üí Transform_B ‚Üí final_table

    –°—Ü–µ–Ω–∞—Ä–∏–π:
    1. –í T1 (16:21): Transform_A —Å–æ–∑–¥–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ intermediate_table (update_ts=T1)
    2. –í T2 (20:04): Transform_B –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç intermediate_table
       - process_ts –≤ Transform_B.meta = T2
       - update_ts –≤ intermediate_table –æ—Å—Ç–∞–µ—Ç—Å—è = T1
       - offset(Transform_B, intermediate_table) = T1
    3. –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ source_table
    4. –í T3: Transform_A –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ (update_ts=T3 –≤ intermediate)
    5. –í T4: Transform_B –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
       - –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ offset optimization —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ
       - –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Å—Ç–∞—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –ø–æ–≤—Ç–æ—Ä–Ω–æ
    """
    ds = DataStore(dbconn, create_meta_table=True)

    # ========== –°–û–ó–î–ê–ù–ò–ï –¢–ê–ë–õ–ò–¶ ==========
    # Source table
    source_store = TableStoreDB(
        dbconn,
        "hyp3_source",
        [Column("id", String, primary_key=True), Column("value", Integer)],
        create_table=True,
    )
    source_table = ds.create_table("hyp3_source", source_store)

    # Intermediate table (output Transform_A, input Transform_B)
    intermediate_store = TableStoreDB(
        dbconn,
        "hyp3_intermediate",
        [Column("id", String, primary_key=True), Column("value_doubled", Integer)],
        create_table=True,
    )
    intermediate_table = ds.create_table("hyp3_intermediate", intermediate_store)

    # Final table (output Transform_B)
    final_store = TableStoreDB(
        dbconn,
        "hyp3_final",
        [Column("id", String, primary_key=True), Column("value_squared", Integer)],
        create_table=True,
    )
    final_table = ds.create_table("hyp3_final", final_store)

    # ========== –°–û–ó–î–ê–ù–ò–ï –¢–†–ê–ù–°–§–û–†–ú–ê–¶–ò–ô ==========
    def double_func(df):
        """Transform_A: —É–¥–≤–∞–∏–≤–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏—è"""
        return df.assign(value_doubled=df["value"] * 2)[["id", "value_doubled"]]

    transform_a = BatchTransformStep(
        ds=ds,
        name="transform_a_double",
        func=double_func,
        input_dts=[ComputeInput(dt=source_table, join_type="full")],
        output_dts=[intermediate_table],
        transform_keys=["id"],
        use_offset_optimization=True,
        chunk_size=10,
    )

    def square_func(df):
        """Transform_B: –≤–æ–∑–≤–æ–¥–∏—Ç –≤ –∫–≤–∞–¥—Ä–∞—Ç"""
        return df.assign(value_squared=df["value_doubled"] ** 2)[["id", "value_squared"]]

    transform_b = BatchTransformStep(
        ds=ds,
        name="transform_b_square",
        func=square_func,
        input_dts=[ComputeInput(dt=intermediate_table, join_type="full")],
        output_dts=[final_table],
        transform_keys=["id"],
        use_offset_optimization=True,
        chunk_size=10,
    )

    # ========== –§–ê–ó–ê 1: T1 (16:21) - Transform_A —Å–æ–∑–¥–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ ==========
    print("\n" + "=" * 80)
    print("–§–ê–ó–ê 1: T1 (16:21) - Transform_A —Å–æ–∑–¥–∞–µ—Ç –ø–µ—Ä–≤—É—é –ø–∞—Ä—Ç–∏—é –¥–∞–Ω–Ω—ã—Ö")
    print("=" * 80)

    base_time = time.time()
    t1 = base_time + 1  # 16:21 –≤ production

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤ source
    source_data_1 = pd.DataFrame({
        "id": [f"rec_{i:02d}" for i in range(5)],
        "value": [1, 2, 3, 4, 5],
    })
    source_table.store_chunk(source_data_1, now=t1)
    time.sleep(0.01)

    # Transform_A –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç source ‚Üí intermediate
    transform_a.run_full(ds=ds, run_config=None)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    intermediate_data = intermediate_table.get_data()
    intermediate_meta = intermediate_table.meta_table.get_metadata()

    print(f"\nIntermediate table –ø–æ—Å–ª–µ Transform_A:")
    print(f"  –ó–∞–ø–∏—Å–µ–π: {len(intermediate_data)}")
    print(f"  update_ts: {intermediate_meta['update_ts'].unique()}")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º update_ts –ø–µ—Ä–≤–æ–π –ø–∞—Ä—Ç–∏–∏
    intermediate_update_ts_phase1 = intermediate_meta['update_ts'].iloc[0]

    assert len(intermediate_data) == 5
    assert (intermediate_data["value_doubled"] == [2, 4, 6, 8, 10]).all()

    # ========== –§–ê–ó–ê 2: T2 (20:04) - Transform_B –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç (–° –ó–ê–î–ï–†–ñ–ö–û–ô!) ==========
    print("\n" + "=" * 80)
    print("–§–ê–ó–ê 2: T2 (20:04) - Transform_B –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç intermediate (4 —á–∞—Å–∞ —Å–ø—É—Å—Ç—è!)")
    print("=" * 80)

    # –°–∏–º—É–ª–∏—Ä—É–µ–º –∑–∞–¥–µ—Ä–∂–∫—É 4 —á–∞—Å–∞
    time.sleep(0.05)  # –í —Ç–µ—Å—Ç–µ - –º–∞–ª–µ–Ω—å–∫–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
    t2 = base_time + 2  # 20:04 –≤ production

    # –ó–∞–ø–æ–º–∏–Ω–∞–µ–º —Ç–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è –ø–µ—Ä–µ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π
    before_transform_b = time.time()

    # Transform_B –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç intermediate ‚Üí final
    transform_b.run_full(ds=ds, run_config=None)

    after_transform_b = time.time()

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    final_data = final_table.get_data()

    # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ Transform_B meta table —á–µ—Ä–µ–∑ SQL
    with ds.meta_dbconn.con.begin() as con:
        transform_b_meta = pd.read_sql(
            sa.select(transform_b.meta_table.sql_table),
            con
        )

    # –ö–†–ò–¢–ò–ß–ù–û: –ø—Ä–æ–≤–µ—Ä—è–µ–º update_ts –≤ intermediate table - –æ–Ω –ù–ï –¥–æ–ª–∂–µ–Ω –∏–∑–º–µ–Ω–∏—Ç—å—Å—è!
    intermediate_meta_after_b = intermediate_table.meta_table.get_metadata()

    print(f"\nIntermediate table –ø–æ—Å–ª–µ Transform_B:")
    print(f"  update_ts: {intermediate_meta_after_b['update_ts'].unique()}")
    print(f"  (–¥–æ–ª–∂–µ–Ω –æ—Å—Ç–∞—Ç—å—Å—è = T1, –ø–æ—Ç–æ–º—É —á—Ç–æ Transform_B —á–∏—Ç–∞–µ—Ç –Ω–æ –ù–ï –ø–∏—à–µ—Ç –≤ intermediate)")

    print(f"\nTransform_B meta table:")
    print(f"  process_ts: {transform_b_meta['process_ts'].unique()}")
    print(f"  (–¥–æ–ª–∂–µ–Ω –±—ã—Ç—å ‚âà T2, —Ç–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏)")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º offset
    offsets_b = ds.offset_table.get_offsets_for_transformation(transform_b.get_name())
    offset_b_intermediate = offsets_b["hyp3_intermediate"]

    print(f"\nOffset –¥–ª—è Transform_B:")
    print(f"  offset(Transform_B, intermediate_table) = {offset_b_intermediate:.2f}")
    print(f"  (–¥–æ–ª–∂–µ–Ω –±—ã—Ç—å = MAX(update_ts –∏–∑ intermediate) ‚âà T1)")

    print(f"\nüîç –†–ê–°–°–ò–ù–•–†–û–ù–ò–ó–ê–¶–ò–Ø:")
    print(f"  update_ts –≤ intermediate = {intermediate_update_ts_phase1:.2f} (T1)")
    print(f"  process_ts –≤ Transform_B = {transform_b_meta['process_ts'].iloc[0]:.2f} (T2)")
    print(f"  –†–∞–∑–Ω–∏—Ü–∞: {transform_b_meta['process_ts'].iloc[0] - intermediate_update_ts_phase1:.2f} —Å–µ–∫")

    # –ü–†–û–í–ï–†–ö–ò
    assert len(final_data) == 5, f"–î–æ–ª–∂–Ω–æ –±—ã—Ç—å 5 –∑–∞–ø–∏—Å–µ–π, –ø–æ–ª—É—á–µ–Ω–æ {len(final_data)}"

    # –ö–†–ò–¢–ò–ß–ù–û: –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –í–°–ï –∑–∞–ø–∏—Å–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã (–Ω–∏—á–µ–≥–æ –Ω–µ –ø–æ—Ç–µ—Ä—è–Ω–æ!)
    expected_ids_phase2 = {f"rec_{i:02d}" for i in range(5)}
    actual_ids_phase2 = set(final_data["id"].tolist())
    lost_ids_phase2 = expected_ids_phase2 - actual_ids_phase2

    if lost_ids_phase2:
        pytest.fail(
            f"üö® –ü–û–¢–ï–†–Ø –î–ê–ù–ù–´–• –í –§–ê–ó–ï 2!\n"
            f"–û–∂–∏–¥–∞–ª–æ—Å—å: {len(expected_ids_phase2)} –∑–∞–ø–∏—Å–µ–π\n"
            f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(actual_ids_phase2)} –∑–∞–ø–∏—Å–µ–π\n"
            f"–ü–û–¢–ï–†–Ø–ù–û: {len(lost_ids_phase2)} –∑–∞–ø–∏—Å–µ–π: {sorted(lost_ids_phase2)}\n"
            f"–≠—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç —á—Ç–æ –≥–∏–ø–æ—Ç–µ–∑–∞ 3 –≤–ª–∏—è–µ—Ç –Ω–∞ –ø–æ—Ç–µ—Ä—é –¥–∞–Ω–Ω—ã—Ö!"
        )

    print(f"\n‚úì –í–°–ï –∑–∞–ø–∏—Å–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã: {len(actual_ids_phase2)}/{len(expected_ids_phase2)}")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è
    assert (final_data["value_squared"] == [4, 16, 36, 64, 100]).all()

    # update_ts –≤ intermediate –ù–ï –¥–æ–ª–∂–µ–Ω –∏–∑–º–µ–Ω–∏—Ç—å—Å—è (Transform_B —Ç–æ–ª—å–∫–æ —á–∏—Ç–∞–µ—Ç)
    assert (intermediate_meta_after_b['update_ts'] == intermediate_update_ts_phase1).all(), \
        "update_ts –≤ intermediate table –ù–ï –¥–æ–ª–∂–µ–Ω –∏–∑–º–µ–Ω–∏—Ç—å—Å—è –ø–æ—Å–ª–µ Transform_B"

    # process_ts –≤ Transform_B –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å ‚âà —Ç–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è
    assert all(before_transform_b <= ts <= after_transform_b
               for ts in transform_b_meta['process_ts']), \
        "process_ts –≤ Transform_B –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ç–µ–∫—É—â–∏–º –≤—Ä–µ–º–µ–Ω–µ–º –æ–±—Ä–∞–±–æ—Ç–∫–∏"

    # offset –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å = MAX(update_ts –∏–∑ intermediate) ‚âà T1
    assert abs(offset_b_intermediate - intermediate_update_ts_phase1) < 0.1, \
        "offset –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ä–∞–≤–µ–Ω MAX(update_ts –∏–∑ intermediate)"

    # ========== –§–ê–ó–ê 3: T3 - –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ Transform_A ==========
    print("\n" + "=" * 80)
    print("–§–ê–ó–ê 3: T3 - –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —á–µ—Ä–µ–∑ Transform_A")
    print("=" * 80)

    time.sleep(0.01)
    t3 = base_time + 3

    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ source
    source_data_2 = pd.DataFrame({
        "id": [f"rec_{i:02d}" for i in range(5, 10)],
        "value": [6, 7, 8, 9, 10],
    })
    source_table.store_chunk(source_data_2, now=t3)
    time.sleep(0.01)

    # Transform_A –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    transform_a.run_full(ds=ds, run_config=None)

    intermediate_data_after_new = intermediate_table.get_data()
    print(f"\nIntermediate table –ø–æ—Å–ª–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö:")
    print(f"  –ó–∞–ø–∏—Å–µ–π: {len(intermediate_data_after_new)}")

    assert len(intermediate_data_after_new) == 10

    # ========== –§–ê–ó–ê 4: T4 - Transform_B –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ ==========
    print("\n" + "=" * 80)
    print("–§–ê–ó–ê 4: T4 - Transform_B –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¢–û–õ–¨–ö–û –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ")
    print("=" * 80)

    time.sleep(0.01)
    t4 = base_time + 4

    # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π –≤ transform_b.meta –î–û –æ–±—Ä–∞–±–æ—Ç–∫–∏
    with ds.meta_dbconn.con.begin() as con:
        transform_b_meta_before = pd.read_sql(
            sa.select(transform_b.meta_table.sql_table),
            con
        )
    process_ts_before = dict(zip(transform_b_meta_before['id'], transform_b_meta_before['process_ts']))

    print(f"\nTransform_B meta –î–û –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö:")
    print(f"  –ó–∞–ø–∏—Å–µ–π: {len(transform_b_meta_before)}")
    print(f"  process_ts –¥–ª—è —Å—Ç–∞—Ä—ã—Ö –∑–∞–ø–∏—Å–µ–π (rec_00): {process_ts_before.get('rec_00', 'N/A')}")

    # Transform_B –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º offset
    transform_b.run_full(ds=ds, run_config=None)

    final_data_after_new = final_table.get_data()
    with ds.meta_dbconn.con.begin() as con:
        transform_b_meta_after = pd.read_sql(
            sa.select(transform_b.meta_table.sql_table),
            con
        )
    process_ts_after = dict(zip(transform_b_meta_after['id'], transform_b_meta_after['process_ts']))

    print(f"\nTransform_B meta –ü–û–°–õ–ï –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö:")
    print(f"  –ó–∞–ø–∏—Å–µ–π: {len(transform_b_meta_after)}")
    print(f"  process_ts –¥–ª—è —Å—Ç–∞—Ä—ã—Ö –∑–∞–ø–∏—Å–µ–π (rec_00): {process_ts_after.get('rec_00', 'N/A')}")
    print(f"  process_ts –¥–ª—è –Ω–æ–≤—ã—Ö –∑–∞–ø–∏—Å–µ–π (rec_05): {process_ts_after.get('rec_05', 'N/A')}")

    # –ö–†–ò–¢–ò–ß–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê: —Å—Ç–∞—Ä—ã–µ –∑–∞–ø–∏—Å–∏ –ù–ï –¥–æ–ª–∂–Ω—ã –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å—Å—è –ø–æ–≤—Ç–æ—Ä–Ω–æ
    old_ids = [f"rec_{i:02d}" for i in range(5)]
    reprocessed_ids = []

    for old_id in old_ids:
        if old_id in process_ts_before and old_id in process_ts_after:
            if abs(process_ts_after[old_id] - process_ts_before[old_id]) > 0.001:
                reprocessed_ids.append(old_id)

    if reprocessed_ids:
        print(f"\nüö® –ü–†–û–ë–õ–ï–ú–ê: –°—Ç–∞—Ä—ã–µ –∑–∞–ø–∏—Å–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã –ü–û–í–¢–û–†–ù–û!")
        print(f"  –ó–∞–ø–∏—Å–∏: {reprocessed_ids}")
        for rid in reprocessed_ids:
            print(f"    {rid}: process_ts –î–û={process_ts_before[rid]:.6f}, "
                  f"–ü–û–°–õ–ï={process_ts_after[rid]:.6f}")
        pytest.fail(
            f"–ì–ò–ü–û–¢–ï–ó–ê 3: –†–∞—Å—Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è update_ts –∏ process_ts –≤—ã–∑–≤–∞–ª–∞ –ø–æ–≤—Ç–æ—Ä–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É!\n"
            f"–°—Ç–∞—Ä—ã–µ –∑–∞–ø–∏—Å–∏ ({reprocessed_ids}) –±—ã–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã –ø–æ–≤—Ç–æ—Ä–Ω–æ.\n"
            f"–≠—Ç–æ —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ –ø—Ä–æ–±–ª–µ–º—É —Å offset optimization –≤ multi-step pipeline."
        )

    # –ö–†–ò–¢–ò–ß–ù–û: –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –í–°–ï –∑–∞–ø–∏—Å–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã (–Ω–∏—á–µ–≥–æ –Ω–µ –ø–æ—Ç–µ—Ä—è–Ω–æ!)
    expected_ids_phase4 = {f"rec_{i:02d}" for i in range(10)}  # rec_00..rec_09
    actual_ids_phase4 = set(final_data_after_new["id"].tolist())
    lost_ids_phase4 = expected_ids_phase4 - actual_ids_phase4

    if lost_ids_phase4:
        pytest.fail(
            f"üö® –ü–û–¢–ï–†–Ø –î–ê–ù–ù–´–• –í –§–ê–ó–ï 4!\n"
            f"–û–∂–∏–¥–∞–ª–æ—Å—å: {len(expected_ids_phase4)} –∑–∞–ø–∏—Å–µ–π\n"
            f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(actual_ids_phase4)} –∑–∞–ø–∏—Å–µ–π\n"
            f"–ü–û–¢–ï–†–Ø–ù–û: {len(lost_ids_phase4)} –∑–∞–ø–∏—Å–µ–π: {sorted(lost_ids_phase4)}\n\n"
            f"–î–µ—Ç–∞–ª–∏:\n"
            f"  –°—Ç–∞—Ä—ã–µ –∑–∞–ø–∏—Å–∏ (–¥–æ–ª–∂–Ω—ã –æ—Å—Ç–∞—Ç—å—Å—è): rec_00..rec_04\n"
            f"  –ù–æ–≤—ã–µ –∑–∞–ø–∏—Å–∏ (–¥–æ–ª–∂–Ω—ã –¥–æ–±–∞–≤–∏—Ç—å—Å—è): rec_05..rec_09\n"
            f"  –§–∞–∫—Ç–∏—á–µ—Å–∫–∏ –ø–æ—Ç–µ—Ä—è–Ω–Ω—ã–µ: {sorted(lost_ids_phase4)}\n\n"
            f"–≠—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç —á—Ç–æ –≥–∏–ø–æ—Ç–µ–∑–∞ 3 (—Ä–∞—Å—Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è update_ts/process_ts)\n"
            f"–≤–ª–∏—è–µ—Ç –Ω–∞ –ø–æ—Ç–µ—Ä—é –¥–∞–Ω–Ω—ã—Ö –≤ multi-step pipeline!"
        )

    print(f"\n‚úì –í–°–ï –∑–∞–ø–∏—Å–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã: {len(actual_ids_phase4)}/{len(expected_ids_phase4)}")
    print(f"  –°—Ç–∞—Ä—ã–µ –∑–∞–ø–∏—Å–∏ (rec_00..rec_04): {all(f'rec_{i:02d}' in actual_ids_phase4 for i in range(5))}")
    print(f"  –ù–æ–≤—ã–µ –∑–∞–ø–∏—Å–∏ (rec_05..rec_09): {all(f'rec_{i:02d}' in actual_ids_phase4 for i in range(5, 10))}")

    # –ü–†–û–í–ï–†–ö–ò
    assert len(final_data_after_new) == 10, f"–î–æ–ª–∂–Ω–æ –±—ã—Ç—å 10 –∑–∞–ø–∏—Å–µ–π, –ø–æ–ª—É—á–µ–Ω–æ {len(final_data_after_new)}"

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã
    expected_values = [4, 16, 36, 64, 100, 144, 196, 256, 324, 400]  # (value*2)^2
    actual_values_sorted = sorted(final_data_after_new["value_squared"].tolist())
    assert actual_values_sorted == expected_values, \
        f"–ó–Ω–∞—á–µ–Ω–∏—è –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç. –û–∂–∏–¥–∞–ª–æ—Å—å: {expected_values}, –ø–æ–ª—É—á–µ–Ω–æ: {actual_values_sorted}"

    print(f"\n‚úÖ –ì–ò–ü–û–¢–ï–ó–ê 3: –†–∞—Å—Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è update_ts –∏ process_ts –ù–ï –≤—ã–∑—ã–≤–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º")
    print(f"‚úì –°—Ç–∞—Ä—ã–µ –∑–∞–ø–∏—Å–∏ –ù–ï –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã –ø–æ–≤—Ç–æ—Ä–Ω–æ")
    print(f"‚úì –ù–æ–≤—ã–µ –∑–∞–ø–∏—Å–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
    print(f"‚úì –í—Å–µ –∑–∞–ø–∏—Å–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã, –ù–ò–ß–ï–ì–û –Ω–µ –ø–æ—Ç–µ—Ä—è–Ω–æ")
    print(f"‚úì offset optimization —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –≤ multi-step pipeline")
    print(f"\n–û–±—ä—è—Å–Ω–µ–Ω–∏–µ:")
    print(f"  - –£ –∫–∞–∂–¥–æ–π —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –°–í–û–Ø meta table —Å –°–í–û–ò–ú process_ts")
    print(f"  - Transform_B –∏—Å–ø–æ–ª—å–∑—É–µ—Ç offset –Ω–∞ –æ—Å–Ω–æ–≤–µ update_ts –∏–∑ intermediate table")
    print(f"  - process_ts –≤ Transform_B.meta –ù–ï —Å–≤—è–∑–∞–Ω —Å update_ts –≤ intermediate")
    print(f"  - –†–∞—Å—Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –ù–ï –≤–ª–∏—è–µ—Ç –Ω–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å offset optimization")


def test_hypothesis_3_explanation():
    """
    –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –≥–∏–ø–æ—Ç–µ–∑—ã 3.

    –í–û–ü–†–û–°: –ü–æ—á–µ–º—É —Ä–∞—Å—Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è update_ts –∏ process_ts –Ω–µ –≤–ª–∏—è–µ—Ç –Ω–∞ offset optimization?

    –û–¢–í–ï–¢:
    1. –£ –∫–∞–∂–¥–æ–π —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –°–í–û–Ø TransformMetaTable —Å –°–í–û–ò–ú process_ts
    2. offset(Transform_B, TableA) = MAX(update_ts –∏–∑ TableA)
    3. process_ts –≤ Transform_B.meta –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ –æ–±—Ä–∞–±–æ—Ç–∫–µ Transform_B
    4. –û–Ω–∏ –Ω–µ –ø–µ—Ä–µ—Å–µ–∫–∞—é—Ç—Å—è!

    –ê–†–•–ò–¢–ï–ö–¢–£–†–ê:

    source_table ‚Üí Transform_A ‚Üí intermediate_table ‚Üí Transform_B ‚Üí final_table
                    [Meta_A]                            [Meta_B]

    - Meta_A.process_ts = –∫–æ–≥–¥–∞ Transform_A –æ–±—Ä–∞–±–æ—Ç–∞–ª –∑–∞–ø–∏—Å–∏
    - intermediate_table.update_ts = –∫–æ–≥–¥–∞ Transform_A –∑–∞–ø–∏—Å–∞–ª –¥–∞–Ω–Ω—ã–µ
    - offset(Transform_B, intermediate) = MAX(intermediate_table.update_ts)
    - Meta_B.process_ts = –∫–æ–≥–¥–∞ Transform_B –æ–±—Ä–∞–±–æ—Ç–∞–ª –∑–∞–ø–∏—Å–∏

    –í–ê–ñ–ù–û:
    - Transform_B –ù–ï —Å–º–æ—Ç—Ä–∏—Ç –Ω–∞ Meta_A.process_ts
    - Transform_B –∏—Å–ø–æ–ª—å–∑—É–µ—Ç intermediate_table.update_ts –¥–ª—è offset
    - –†–∞—Å—Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –º–µ–∂–¥—É Meta_A.process_ts –∏ intermediate_table.update_ts –Ω–µ –≤–∞–∂–Ω–∞

    –ö–û–ì–î–ê –ù–£–ñ–ù–ê –ü–†–û–í–ï–†–ö–ê process_ts:
    –ü—Ä–æ–≤–µ—Ä–∫–∞ process_ts –Ω—É–∂–Ω–∞ –¥–ª—è –û–î–ù–û–ô —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏, —á—Ç–æ–±—ã –Ω–µ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å
    –æ–¥–Ω–∏ –∏ —Ç–µ –∂–µ –¥–∞–Ω–Ω—ã–µ –¥–≤–∞–∂–¥—ã –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ > –Ω–∞ >=.

    –ù–æ —ç—Ç–æ –ø—Ä–æ–≤–µ—Ä–∫–∞ –°–í–û–ï–ì–û process_ts (Transform_B.meta.process_ts),
    –∞ –Ω–µ process_ts –¥—Ä—É–≥–∏—Ö —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–π!
    """
    pass


if __name__ == "__main__":
    from datapipe.store.database import DBConn
    from sqlalchemy import create_engine, text

    DBCONNSTR = "postgresql://postgres:password@localhost:5432/postgres"
    DB_TEST_SCHEMA = "test_hypothesis_3_multi_step"

    eng = create_engine(DBCONNSTR)
    try:
        with eng.begin() as conn:
            conn.execute(text(f"DROP SCHEMA {DB_TEST_SCHEMA} CASCADE"))
    except Exception:
        pass

    with eng.begin() as conn:
        conn.execute(text(f"CREATE SCHEMA {DB_TEST_SCHEMA}"))

    test_dbconn = DBConn(DBCONNSTR, DB_TEST_SCHEMA)

    print("–ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∞ –≥–∏–ø–æ—Ç–µ–∑—ã 3 (multi-step pipeline)...")
    test_hypothesis_3_multi_step_pipeline_update_ts_vs_process_ts_desync(test_dbconn)
