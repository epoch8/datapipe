"""
üö® –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô PRODUCTION –ë–ê–ì: Offset Optimization —Ç–µ—Ä—è–µ—Ç –¥–∞–Ω–Ω—ã–µ

–ü–†–û–ë–õ–ï–ú–ê –í PRODUCTION:
- –î–∞—Ç–∞: 08.12.2025
- –ü–æ—Ç–µ—Ä—è–Ω–æ: 48,915 –∏–∑ 82,000 –∑–∞–ø–∏—Å–µ–π (60%)
- –ü—Ä–∏—á–∏–Ω–∞: –°—Ç—Ä–æ–≥–æ–µ –Ω–µ—Ä–∞–≤–µ–Ω—Å—Ç–≤–æ –≤ WHERE update_ts > offset

–ö–û–†–ù–ï–í–ê–Ø –ü–†–ò–ß–ò–ù–ê:
–ö–æ–¥: datapipe/meta/sql_meta.py:967
  tbl.c.update_ts > offset  # ‚ùå –û–®–ò–ë–ö–ê! –î–æ–ª–∂–Ω–æ –±—ã—Ç—å >=

–ú–ï–•–ê–ù–ò–ó–ú –ë–ê–ì–ê:
1. –ë–∞—Ç—á –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∑–∞–ø–∏—Å–∏ –≤ ORDER BY (id, hashtag) - –ù–ï –ø–æ –≤—Ä–µ–º–µ–Ω–∏!
2. –ë–∞—Ç—á —Å–æ–¥–µ—Ä–∂–∏—Ç –∑–∞–ø–∏—Å–∏ —Å –†–ê–ó–ù–´–ú–ò update_ts
3. offset = MAX(update_ts) –∏–∑ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–≥–æ –±–∞—Ç—á–∞
4. –°–ª–µ–¥—É—é—â–∏–π –∑–∞–ø—É—Å–∫: WHERE update_ts > offset (—Å—Ç—Ä–æ–≥–æ–µ –Ω–µ—Ä–∞–≤–µ–Ω—Å—Ç–≤–æ!)
5. –ó–∞–ø–∏—Å–∏ —Å update_ts == offset –Ω–æ –Ω–µ –≤–æ—à–µ–¥—à–∏–µ –≤ –±–∞—Ç—á –¢–ï–†–Ø–Æ–¢–°–Ø

–í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø –ü–†–û–ë–õ–ï–ú–´:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ –í—Ä–µ–º–µ–Ω–Ω–∞—è —à–∫–∞–ª–∞ (update_ts):                                       ‚îÇ
‚îÇ                                                                     ‚îÇ
‚îÇ T1 (16:21)  T2 (17:00)  T3 (18:00)  T4 (19:00)  T5 (20:29)        ‚îÇ
‚îÇ     ‚îÇ           ‚îÇ           ‚îÇ           ‚îÇ           ‚îÇ               ‚îÇ
‚îÇ     ‚ñº           ‚ñº           ‚ñº           ‚ñº           ‚ñº               ‚îÇ
‚îÇ  rec_00      rec_08      rec_13      rec_18      rec_22            ‚îÇ
‚îÇ  rec_01      rec_09      rec_14      rec_19      rec_23            ‚îÇ
‚îÇ  ...         rec_10      rec_15      rec_20      rec_24            ‚îÇ
‚îÇ  rec_07      rec_11      rec_16      rec_21                        ‚îÇ
‚îÇ              rec_12      rec_17                                     ‚îÇ
‚îÇ                                                                     ‚îÇ
‚îÇ ORDER BY id (—Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏):                            ‚îÇ
‚îÇ rec_00 ‚Üí rec_01 ‚Üí ... ‚Üí rec_07 ‚Üí rec_08 ‚Üí rec_09 ‚Üí rec_10 ‚Üí ...   ‚îÇ
‚îÇ   T1      T1           T1        T2        T2        T2            ‚îÇ
‚îÇ                                                                     ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                       ‚îÇ
‚îÇ ‚îÇ –ë–ê–¢–ß 1 (chunk_size=10)   ‚îÇ                                       ‚îÇ
‚îÇ ‚îÇ rec_00 –¥–æ rec_09         ‚îÇ                                       ‚îÇ
‚îÇ ‚îÇ update_ts: T1...T1, T2   ‚îÇ                                       ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                       ‚îÇ
‚îÇ           ‚Üì                                                         ‚îÇ
‚îÇ    offset = MAX(T1, T2) = T2                                       ‚îÇ
‚îÇ                                                                     ‚îÇ
‚îÇ –°–ª–µ–¥—É—é—â–∏–π –∑–∞–ø—É—Å–∫:                                                  ‚îÇ
‚îÇ WHERE update_ts > T2  ‚Üê –°–¢–†–û–ì–û–ï –ù–ï–†–ê–í–ï–ù–°–¢–í–û!                      ‚îÇ
‚îÇ                                                                     ‚îÇ
‚îÇ üö® –ü–û–¢–ï–†–Ø–ù–´:                                                       ‚îÇ
‚îÇ    rec_10, rec_11, rec_12  (update_ts = T2 == offset)             ‚îÇ
‚îÇ                                                                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

–†–ï–®–ï–ù–ò–ï:
–ó–∞–º–µ–Ω–∏—Ç—å > –Ω–∞ >= –≤ sql_meta.py:967:
  tbl.c.update_ts >= offset  # ‚úÖ –ü–†–ê–í–ò–õ–¨–ù–û
"""

import time
from typing import List, Tuple

import pandas as pd
import pytest
from sqlalchemy import Column, Integer, String

from datapipe.compute import ComputeInput
from datapipe.datatable import DataStore
from datapipe.step.batch_transform import BatchTransformStep
from datapipe.store.database import DBConn, TableStoreDB


# ============================================================================
# –ü–û–î–ì–û–¢–û–í–ö–ê –¢–ï–°–¢–û–í–´–• –î–ê–ù–ù–´–•
# ============================================================================

def prepare_test_data() -> List[Tuple[str, str, float]]:
    """
    –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è production –±–∞–≥–∞.

    –î–∞–Ω–Ω—ã–µ –∏–º–∏—Ç–∏—Ä—É—é—Ç –Ω–∞–∫–æ–ø–ª–µ–Ω–∏–µ –∑–∞–ø–∏—Å–µ–π –≤ —Ç–µ—á–µ–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —á–∞—Å–æ–≤
    —Å –†–ê–ó–ù–´–ú–ò update_ts (–∫–∞–∫ –≤ —Ä–µ–∞–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ).

    Returns:
        List[(record_id, label, update_ts_offset)]

    –í—Ä–µ–º–µ–Ω–Ω–∞—è —à–∫–∞–ª–∞:
        T1 = base_time + 1  (16:21 –≤ production)
        T2 = base_time + 2  (17:00)
        T3 = base_time + 3  (18:00)
        T4 = base_time + 4  (19:00)
        T5 = base_time + 5  (20:29 –≤ production)
    """
    # –§–æ—Ä–º–∞—Ç: (id, label –¥–ª—è –ª–æ–≥–æ–≤, —Å–º–µ—â–µ–Ω–∏–µ timestamp –æ—Ç base_time)
    test_data = [
        # –ì—Ä—É–ø–ø–∞ 1: T1 (16:21) - 8 –∑–∞–ø–∏—Å–µ–π
        ("rec_00", "T1", 1.0),
        ("rec_01", "T1", 1.0),
        ("rec_02", "T1", 1.0),
        ("rec_03", "T1", 1.0),
        ("rec_04", "T1", 1.0),
        ("rec_05", "T1", 1.0),
        ("rec_06", "T1", 1.0),
        ("rec_07", "T1", 1.0),

        # –ì—Ä—É–ø–ø–∞ 2: T2 (17:00) - 5 –∑–∞–ø–∏—Å–µ–π
        # ‚ö†Ô∏è –ö–†–ò–¢–ò–ß–ù–û: rec_08 –∏ rec_09 –≤–æ–π–¥—É—Ç –≤ –ü–ï–†–í–´–ô –±–∞—Ç—á
        #              rec_10, rec_11, rec_12 –æ—Å—Ç–∞–Ω—É—Ç—Å—è –Ω–∞ –í–¢–û–†–û–ô –±–∞—Ç—á
        ("rec_08", "T2", 2.0),
        ("rec_09", "T2", 2.0),
        ("rec_10", "T2", 2.0),  # üö® –ë–£–î–ï–¢ –ü–û–¢–ï–†–Ø–ù–ê
        ("rec_11", "T2", 2.0),  # üö® –ë–£–î–ï–¢ –ü–û–¢–ï–†–Ø–ù–ê
        ("rec_12", "T2", 2.0),  # üö® –ë–£–î–ï–¢ –ü–û–¢–ï–†–Ø–ù–ê

        # –ì—Ä—É–ø–ø–∞ 3: T3 (18:00) - 5 –∑–∞–ø–∏—Å–µ–π
        ("rec_13", "T3", 3.0),
        ("rec_14", "T3", 3.0),
        ("rec_15", "T3", 3.0),
        ("rec_16", "T3", 3.0),
        ("rec_17", "T3", 3.0),

        # –ì—Ä—É–ø–ø–∞ 4: T4 (19:00) - 4 –∑–∞–ø–∏—Å–∏
        ("rec_18", "T4", 4.0),
        ("rec_19", "T4", 4.0),
        ("rec_20", "T4", 4.0),
        ("rec_21", "T4", 4.0),

        # –ì—Ä—É–ø–ø–∞ 5: T5 (20:29) - 3 –∑–∞–ø–∏—Å–∏
        ("rec_22", "T5", 5.0),
        ("rec_23", "T5", 5.0),
        ("rec_24", "T5", 5.0),
    ]

    return test_data


def print_test_data_visualization(test_data: List[Tuple[str, str, float]], base_time: float):
    """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏"""
    print("\n" + "=" * 80)
    print("–ü–û–î–ì–û–¢–û–í–õ–ï–ù–ù–´–ï –¢–ï–°–¢–û–í–´–ï –î–ê–ù–ù–´–ï")
    print("=" * 80)
    print("\n–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π:", len(test_data))
    print("\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–º –º–µ—Ç–∫–∞–º:")

    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ timestamp
    by_timestamp = {}
    for record_id, label, offset in test_data:
        ts = base_time + offset
        if ts not in by_timestamp:
            by_timestamp[ts] = []
        by_timestamp[ts].append((record_id, label))

    for ts in sorted(by_timestamp.keys()):
        records = by_timestamp[ts]
        label = records[0][1]
        ids = [r[0] for r in records]
        print(f"  {label}: {len(records)} –∑–∞–ø–∏—Å–µ–π - {', '.join(ids)}")

    print("\n–û–∂–∏–¥–∞–µ–º–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –±–∞—Ç—á–∞–º (chunk_size=10, ORDER BY id):")
    print("  –ë–∞—Ç—á 1: rec_00 –¥–æ rec_09  (10 –∑–∞–ø–∏—Å–µ–π)")
    print("          update_ts: T1(8 –∑–∞–ø–∏—Å–µ–π), T2(2 –∑–∞–ø–∏—Å–∏)")
    print("          offset –ø–æ—Å–ª–µ –±–∞—Ç—á–∞ = MAX(T1, T2) = T2")
    print()
    print("  üö® –ö–†–ò–¢–ò–ß–ù–û: –°–ª–µ–¥—É—é—â–∏–π –∑–∞–ø—É—Å–∫ WHERE update_ts > T2")
    print("     –ü–†–û–ü–£–°–¢–ò–¢: rec_10, rec_11, rec_12 (update_ts == T2)")
    print()


# ============================================================================
# PRODUCTION –ë–ê–ì –¢–ï–°–¢
# ============================================================================

def test_production_bug_offset_loses_records_with_equal_update_ts(dbconn: DBConn):
    """
    üö® –í–û–°–ü–†–û–ò–ó–í–û–î–ò–¢ PRODUCTION –ë–ê–ì: 48,915 –∑–∞–ø–∏—Å–µ–π –ø–æ—Ç–µ—Ä—è–Ω–æ (60%)

    –°—Ü–µ–Ω–∞—Ä–∏–π (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è production):
    1. –ù–∞–∫–∞–ø–ª–∏–≤–∞–µ—Ç—Å—è 25 –∑–∞–ø–∏—Å–µ–π —Å —Ä–∞–∑–Ω—ã–º–∏ update_ts (chunk_size=10)
    2. –ü–ï–†–í–´–ô –∑–∞–ø—É—Å–∫ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –¢–û–õ–¨–ö–û –ø–µ—Ä–≤—ã–π –±–∞—Ç—á (10 –∑–∞–ø–∏—Å–µ–π)
    3. offset = MAX(update_ts) –∏–∑ —ç—Ç–∏—Ö 10 = T2
    4. –í–¢–û–†–û–ô –∑–∞–ø—É—Å–∫: WHERE update_ts > T2 (—Å—Ç—Ä–æ–≥–æ–µ –Ω–µ—Ä–∞–≤–µ–Ω—Å—Ç–≤–æ!)
    5. –ó–∞–ø–∏—Å–∏ —Å update_ts == T2 –Ω–æ –Ω–µ –≤–æ—à–µ–¥—à–∏–µ –≤ –ø–µ—Ä–≤—ã–π –±–∞—Ç—á –ü–û–¢–ï–†–Ø–ù–´

    –í production:
    - 82,000 –∑–∞–ø–∏—Å–µ–π –Ω–∞–∫–æ–ø–ª–µ–Ω–æ
    - chunk_size=1000
    - –ü–æ—Ç–µ—Ä—è–Ω–æ 48,915 –∑–∞–ø–∏—Å–µ–π (60%)

    –ú–µ—Ö–∞–Ω–∏–∑–º —Ç–æ—Ç –∂–µ - —Å—Ç—Ä–æ–≥–æ–µ –Ω–µ—Ä–∞–≤–µ–Ω—Å—Ç–≤–æ –≤ —Ñ–∏–ª—å—Ç—Ä–µ offset.
    """
    # ========== SETUP ==========
    ds = DataStore(dbconn, create_meta_table=True)

    input_store = TableStoreDB(
        dbconn,
        "production_bug_input",
        [
            Column("id", String, primary_key=True),
            Column("value", Integer),
        ],
        create_table=True,
    )
    input_dt = ds.create_table("production_bug_input", input_store)

    output_store = TableStoreDB(
        dbconn,
        "production_bug_output",
        [
            Column("id", String, primary_key=True),
            Column("value", Integer),
        ],
        create_table=True,
    )
    output_dt = ds.create_table("production_bug_output", output_store)

    def copy_func(df):
        """–ü—Ä–æ—Å—Ç–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è (–∫–∞–∫ copy_to_online –≤ production)"""
        return df[["id", "value"]]

    step = BatchTransformStep(
        ds=ds,
        name="production_bug_copy",
        func=copy_func,
        input_dts=[ComputeInput(dt=input_dt, join_type="full")],
        output_dts=[output_dt],
        transform_keys=["id"],
        use_offset_optimization=True,
        chunk_size=10,  # –ú–∞–ª–µ–Ω—å–∫–∏–π –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∞ (–≤ production=1000)
    )

    # ========== –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–• ==========
    base_time = time.time()
    test_data = prepare_test_data()

    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
    print_test_data_visualization(test_data, base_time)

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≥—Ä—É–ø–ø–∞–º–∏ –ø–æ timestamp
    for record_id, label, offset in test_data:
        ts = base_time + offset
        input_dt.store_chunk(
            pd.DataFrame({"id": [record_id], "value": [int(offset * 100)]}),
            now=ts
        )
        time.sleep(0.001)  # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ timestamp

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    all_meta = input_dt.meta_table.get_metadata()
    print(f"\n‚úì –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {len(all_meta)}")

    # ========== –ü–ï–†–í–´–ô –ó–ê–ü–£–°–ö (—Ç–æ–ª—å–∫–æ 1 –±–∞—Ç—á) ==========
    print("\n" + "=" * 80)
    print("–ü–ï–†–í–´–ô –ó–ê–ü–£–°–ö –¢–†–ê–ù–°–§–û–†–ú–ê–¶–ò–ò (–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–æ–ª—å–∫–æ 1 –±–∞—Ç—á–∞)")
    print("=" * 80)

    # –ò–º–∏—Ç–∏—Ä—É–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–π –∑–∞–ø—É—Å–∫ –¥–∂–æ–±—ã: –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¢–û–õ–¨–ö–û –ø–µ—Ä–≤—ã–π –±–∞—Ç—á
    (idx_count, idx_gen) = step.get_full_process_ids(ds=ds, run_config=None)
    print(f"–ë–∞—Ç—á–µ–π –¥–æ—Å—Ç—É–ø–Ω–æ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {idx_count}")

    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¢–û–õ–¨–ö–û –ø–µ—Ä–≤—ã–π –±–∞—Ç—á (–∫–∞–∫ –µ—Å–ª–∏ –±—ã –¥–∂–æ–±–∞ –∑–∞–≤–µ—Ä—à–∏–ª–∞—Å—å –ø–æ—Å–ª–µ –Ω–µ–≥–æ)
    first_batch_idx = next(idx_gen)
    idx_gen.close()  # –ó–∞–∫—Ä—ã–≤–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä, —á—Ç–æ–±—ã –æ—Å–≤–æ–±–æ–¥–∏—Ç—å —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –ë–î
    print(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–π –±–∞—Ç—á, —Ä–∞–∑–º–µ—Ä: {len(first_batch_idx)}")
    step.run_idx(ds=ds, idx=first_batch_idx, run_config=None)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º offset –ø–æ—Å–ª–µ –ø–µ—Ä–≤–æ–≥–æ –∑–∞–ø—É—Å–∫–∞
    offsets = ds.offset_table.get_offsets_for_transformation(step.get_name())
    offset_after_first = offsets["production_bug_input"]

    output_after_first = output_dt.get_data()

    print(f"\n‚úì –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞–ø–∏—Å–µ–π: {len(output_after_first)}")
    print(f"‚úì offset —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –Ω–∞: {offset_after_first:.2f}")

    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–∞–∫–∏–µ –∑–∞–ø–∏—Å–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã
    processed_ids = sorted(output_after_first["id"].tolist())
    print(f"‚úì –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ id: {', '.join(processed_ids[:5])}...{', '.join(processed_ids[-2:])}")

    # ========== –ê–ù–ê–õ–ò–ó ==========
    print("\n" + "=" * 80)
    print("–ê–ù–ê–õ–ò–ó: –ö–∞–∫–∏–µ –∑–∞–ø–∏—Å–∏ –æ—Å—Ç–∞–Ω—É—Ç—Å—è –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º–∏?")
    print("=" * 80)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω –±–∞—Ç—á
    if len(output_after_first) >= len(test_data):
        pytest.fail(
            f"–û–®–ò–ë–ö–ê –í –¢–ï–°–¢–ï: –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(output_after_first)} –∑–∞–ø–∏—Å–µ–π, "
            f"–æ–∂–∏–¥–∞–ª–æ—Å—å ~10 (–æ–¥–∏–Ω –±–∞—Ç—á). –¢–µ—Å—Ç –Ω–µ —Å–∏–º—É–ª–∏—Ä—É–µ—Ç –æ—Ç–¥–µ–ª—å–Ω—ã–µ –∑–∞–ø—É—Å–∫–∏."
        )

    print(f"‚úì –û–±—Ä–∞–±–æ—Ç–∞–Ω —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω –±–∞—Ç—á: {len(output_after_first)} –∏–∑ {len(test_data)} –∑–∞–ø–∏—Å–µ–π")

    # –ù–∞—Ö–æ–¥–∏–º –∑–∞–ø–∏—Å–∏ –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥—É—Ç –ø–æ—Ç–µ—Ä—è–Ω—ã
    all_ids = set([rec[0] for rec in test_data])
    processed_ids_set = set(output_after_first["id"].tolist())
    unprocessed_ids = all_ids - processed_ids_set

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∫–∏–µ –∏–∑ –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π –∏–º–µ—é—Ç update_ts <= offset
    lost_records = []
    for record_id, label, offset_val in test_data:
        if record_id in unprocessed_ids:
            ts = base_time + offset_val
            if ts <= offset_after_first:
                lost_records.append((record_id, label, ts))

    if lost_records:
        print(f"\nüö® –û–ë–ù–ê–†–£–ñ–ï–ù–´ –ó–ê–ü–ò–°–ò –ö–û–¢–û–†–´–ï –ë–£–î–£–¢ –ü–û–¢–ï–†–Ø–ù–´: {len(lost_records)}")
        print("   –≠—Ç–∏ –∑–∞–ø–∏—Å–∏ –∏–º–µ—é—Ç update_ts <= offset, –Ω–æ –ù–ï –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã!")
        for record_id, label, ts in lost_records:
            status = "==" if abs(ts - offset_after_first) < 0.01 else "<"
            print(f"   {record_id:10} ({label}) update_ts {status} offset")

    # ========== –í–¢–û–†–û–ô –ó–ê–ü–£–°–ö ==========
    print("\n" + "=" * 80)
    print("–í–¢–û–†–û–ô –ó–ê–ü–£–°–ö –¢–†–ê–ù–°–§–û–†–ú–ê–¶–ò–ò (–∏–º–∏—Ç–∞—Ü–∏—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ –¥–∂–æ–±—ã)")
    print("=" * 80)

    # –ü–æ–ª—É—á–∞–µ–º –±–∞—Ç—á–∏ –¥–ª—è –≤—Ç–æ—Ä–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ (—Å —É—á–µ—Ç–æ–º offset)
    (idx_count_second, idx_gen_second) = step.get_full_process_ids(ds=ds, run_config=None)
    print(f"–ë–∞—Ç—á–µ–π –¥–æ—Å—Ç—É–ø–Ω–æ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {idx_count_second}")

    if idx_count_second > 0:
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –±–∞—Ç—á–∏
        for idx in idx_gen_second:
            print(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á, —Ä–∞–∑–º–µ—Ä: {len(idx)}")
            step.run_idx(ds=ds, idx=idx, run_config=None)
        idx_gen_second.close()  # –ó–∞–∫—Ä—ã–≤–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –ø–æ—Å–ª–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

    # ========== –ü–†–û–í–ï–†–ö–ê –†–ï–ó–£–õ–¨–¢–ê–¢–ê ==========
    final_output = output_dt.get_data()
    final_processed_ids = set(final_output["id"].tolist())

    print(f"\n–§–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:")
    print(f"  –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π –≤ input:  {len(test_data)}")
    print(f"  –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –≤ output:    {len(final_output)}")
    print(f"  –ü–û–¢–ï–†–Ø–ù–û:               {len(all_ids) - len(final_processed_ids)}")

    # –ö–†–ò–¢–ò–ß–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê: –í—Å–µ –ª–∏ –∑–∞–ø–∏—Å–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã?
    if len(final_output) < len(test_data):
        # –ù–∞—Ö–æ–¥–∏–º –ø–æ—Ç–µ—Ä—è–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∏
        lost_ids = all_ids - final_processed_ids
        lost_records_final = []
        for record_id, label, offset_val in test_data:
            if record_id in lost_ids:
                lost_records_final.append((record_id, label, base_time + offset_val))

        print("\n" + "=" * 80)
        print("üö® –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô –ë–ê–ì –í–û–°–ü–†–û–ò–ó–í–ï–î–ï–ù!")
        print("=" * 80)
        print(f"\n–ü–æ—Ç–µ—Ä—è–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∏ ({len(lost_records_final)}):")
        for record_id, label, ts in lost_records_final:
            print(f"  {record_id:10} ({label}) update_ts={ts:.2f} {'==' if abs(ts - offset_after_first) < 0.01 else '<='} offset={offset_after_first:.2f}")

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ timestamp
        by_label = {}
        for record_id, label, ts in lost_records_final:
            if label not in by_label:
                by_label[label] = []
            by_label[label].append(record_id)

        print(f"\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ—Ç–µ—Ä—è–Ω–Ω—ã—Ö –ø–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–π –º–µ—Ç–∫–µ:")
        for label in sorted(by_label.keys()):
            ids = by_label[label]
            print(f"  {label}: {len(ids)} –∑–∞–ø–∏—Å–µ–π - {', '.join(ids)}")

        pytest.fail(
            f"\nüö® –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô –ë–ê–ì –í OFFSET OPTIMIZATION!\n"
            f"{'=' * 50}\n"
            f"–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π:      {len(test_data)}\n"
            f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ:         {len(final_output)}\n"
            f"–ü–û–¢–ï–†–Ø–ù–û:           {len(lost_records_final)} ({len(lost_records_final)*100/len(test_data):.1f}%)\n"
            f"offset –ø–æ—Å–ª–µ 1-–≥–æ:  {offset_after_first:.2f}\n\n"
            f"–ú–ï–•–ê–ù–ò–ó–ú –ë–ê–ì–ê:\n"
            f"1. –ü–µ—Ä–≤—ã–π –±–∞—Ç—á (10 –∑–∞–ø–∏—Å–µ–π) —Å–æ–¥–µ—Ä–∂–∞–ª –∑–∞–ø–∏—Å–∏ —Å –†–ê–ó–ù–´–ú–ò update_ts\n"
            f"2. offset —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –Ω–∞ MAX(update_ts) = {offset_after_first:.2f}\n"
            f"3. –ó–∞–ø–∏—Å–∏ —Å update_ts == offset –ù–û –Ω–µ –≤–æ—à–µ–¥—à–∏–µ –≤ –ø–µ—Ä–≤—ã–π –±–∞—Ç—á –ü–û–¢–ï–†–Ø–ù–´!\n"
            f"4. –ü—Ä–∏—á–∏–Ω–∞: WHERE update_ts > offset (—Å—Ç—Ä–æ–≥–æ–µ >) –≤–º–µ—Å—Ç–æ >=\n\n"
            f"–í PRODUCTION: 82,000 –∑–∞–ø–∏—Å–µ–π, chunk_size=1000, –ø–æ—Ç–µ—Ä—è–Ω–æ 48,915 (60%)\n"
            f"{'=' * 50}"
        )

    print("\n‚úÖ –í—Å–µ –∑–∞–ø–∏—Å–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")


if __name__ == "__main__":
    # –î–ª—è —Ä—É—á–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ –∏ –æ—Ç–ª–∞–¥–∫–∏
    from datapipe.store.database import DBConn
    from sqlalchemy import create_engine, text

    DBCONNSTR = "postgresql://postgres:password@localhost:5432/postgres"
    DB_TEST_SCHEMA = "test_production_bug"

    eng = create_engine(DBCONNSTR)
    try:
        with eng.begin() as conn:
            conn.execute(text(f"DROP SCHEMA {DB_TEST_SCHEMA} CASCADE"))
    except Exception:
        pass

    with eng.begin() as conn:
        conn.execute(text(f"CREATE SCHEMA {DB_TEST_SCHEMA}"))

    test_dbconn = DBConn(DBCONNSTR, DB_TEST_SCHEMA)

    print("–ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∞ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è production –±–∞–≥–∞...")
    test_production_bug_offset_loses_records_with_equal_update_ts(test_dbconn)
