"""
üö® –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô PRODUCTION –ë–ê–ì: Offset Optimization —Ç–µ—Ä—è–µ—Ç –¥–∞–Ω–Ω—ã–µ

–ü–†–û–ë–õ–ï–ú–ê –í PRODUCTION:
- –î–∞—Ç–∞: 08.12.2025
- –ü–æ—Ç–µ—Ä—è–Ω–æ: 48,915 –∏–∑ 82,000 –∑–∞–ø–∏—Å–µ–π (60%)
- –ü—Ä–∏—á–∏–Ω–∞: –°—Ç—Ä–æ–≥–æ–µ –Ω–µ—Ä–∞–≤–µ–Ω—Å—Ç–≤–æ –≤ WHERE update_ts > offset

–ö–û–†–ù–ï–í–ê–Ø –ü–†–ò–ß–ò–ù–ê:
–ö–æ–¥: datapipe/meta/sql_meta.py:967
  tbl.c.update_ts > offset  # ‚ùå –û–®–ò–ë–ö–ê! –î–æ–ª–∂–Ω–æ –±—ã—Ç—å >=

–ú–ï–•–ê–ù–ò–ó–ú –ë–ê–ì–ê:
1. –ë–∞—Ç—á –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∑–∞–ø–∏—Å–∏ –≤ ORDER BY (id, hashtag) - –ù–ï –ø–æ –≤—Ä–µ–º–µ–Ω–∏!
2. –ë–∞—Ç—á —Å–æ–¥–µ—Ä–∂–∏—Ç –∑–∞–ø–∏—Å–∏ —Å –†–ê–ó–ù–´–ú–ò update_ts
3. offset = MAX(update_ts) –∏–∑ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–≥–æ –±–∞—Ç—á–∞
4. –°–ª–µ–¥—É—é—â–∏–π –∑–∞–ø—É—Å–∫: WHERE update_ts > offset (—Å—Ç—Ä–æ–≥–æ–µ –Ω–µ—Ä–∞–≤–µ–Ω—Å—Ç–≤–æ!)
5. –ó–∞–ø–∏—Å–∏ —Å update_ts == offset –Ω–æ –Ω–µ –≤–æ—à–µ–¥—à–∏–µ –≤ –±–∞—Ç—á –¢–ï–†–Ø–Æ–¢–°–Ø

–í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø –ü–†–û–ë–õ–ï–ú–´:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ –í—Ä–µ–º–µ–Ω–Ω–∞—è —à–∫–∞–ª–∞ (update_ts):                                       ‚îÇ
‚îÇ                                                                     ‚îÇ
‚îÇ T1 (16:21)  T2 (17:00)  T3 (18:00)  T4 (19:00)  T5 (20:29)        ‚îÇ
‚îÇ     ‚îÇ           ‚îÇ           ‚îÇ           ‚îÇ           ‚îÇ               ‚îÇ
‚îÇ     ‚ñº           ‚ñº           ‚ñº           ‚ñº           ‚ñº               ‚îÇ
‚îÇ  rec_00      rec_08      rec_13      rec_18      rec_22            ‚îÇ
‚îÇ  rec_01      rec_09      rec_14      rec_19      rec_23            ‚îÇ
‚îÇ  ...         rec_10      rec_15      rec_20      rec_24            ‚îÇ
‚îÇ  rec_07      rec_11      rec_16      rec_21                        ‚îÇ
‚îÇ              rec_12      rec_17                                     ‚îÇ
‚îÇ                                                                     ‚îÇ
‚îÇ ORDER BY id (—Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏):                            ‚îÇ
‚îÇ rec_00 ‚Üí rec_01 ‚Üí ... ‚Üí rec_07 ‚Üí rec_08 ‚Üí rec_09 ‚Üí rec_10 ‚Üí ...   ‚îÇ
‚îÇ   T1      T1           T1        T2        T2        T2            ‚îÇ
‚îÇ                                                                     ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                       ‚îÇ
‚îÇ ‚îÇ –ë–ê–¢–ß 1 (chunk_size=10)   ‚îÇ                                       ‚îÇ
‚îÇ ‚îÇ rec_00 –¥–æ rec_09         ‚îÇ                                       ‚îÇ
‚îÇ ‚îÇ update_ts: T1...T1, T2   ‚îÇ                                       ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                       ‚îÇ
‚îÇ           ‚Üì                                                         ‚îÇ
‚îÇ    offset = MAX(T1, T2) = T2                                       ‚îÇ
‚îÇ                                                                     ‚îÇ
‚îÇ –°–ª–µ–¥—É—é—â–∏–π –∑–∞–ø—É—Å–∫:                                                  ‚îÇ
‚îÇ WHERE update_ts > T2  ‚Üê –°–¢–†–û–ì–û–ï –ù–ï–†–ê–í–ï–ù–°–¢–í–û!                      ‚îÇ
‚îÇ                                                                     ‚îÇ
‚îÇ üö® –ü–û–¢–ï–†–Ø–ù–´:                                                       ‚îÇ
‚îÇ    rec_10, rec_11, rec_12  (update_ts = T2 == offset)             ‚îÇ
‚îÇ                                                                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

–†–ï–®–ï–ù–ò–ï:
–ó–∞–º–µ–Ω–∏—Ç—å > –Ω–∞ >= –≤ sql_meta.py:967:
  tbl.c.update_ts >= offset  # ‚úÖ –ü–†–ê–í–ò–õ–¨–ù–û
"""

import time
from typing import List, Tuple

import pandas as pd
import pytest
from sqlalchemy import Column, Integer, String

from datapipe.compute import ComputeInput
from datapipe.datatable import DataStore
from datapipe.step.batch_transform import BatchTransformStep
from datapipe.store.database import DBConn, TableStoreDB


# ============================================================================
# –ü–û–î–ì–û–¢–û–í–ö–ê –¢–ï–°–¢–û–í–´–• –î–ê–ù–ù–´–•
# ============================================================================

def prepare_test_data() -> List[Tuple[str, str, float]]:
    """
    –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è production –±–∞–≥–∞.

    –î–∞–Ω–Ω—ã–µ –∏–º–∏—Ç–∏—Ä—É—é—Ç –Ω–∞–∫–æ–ø–ª–µ–Ω–∏–µ –∑–∞–ø–∏—Å–µ–π –≤ —Ç–µ—á–µ–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —á–∞—Å–æ–≤
    —Å –†–ê–ó–ù–´–ú–ò update_ts (–∫–∞–∫ –≤ —Ä–µ–∞–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ).

    Returns:
        List[(record_id, label, update_ts_offset)]

    –í—Ä–µ–º–µ–Ω–Ω–∞—è —à–∫–∞–ª–∞:
        T1 = base_time + 1  (16:21 –≤ production)
        T2 = base_time + 2  (17:00)
        T3 = base_time + 3  (18:00)
        T4 = base_time + 4  (19:00)
        T5 = base_time + 5  (20:29 –≤ production)
    """
    # –§–æ—Ä–º–∞—Ç: (id, label –¥–ª—è –ª–æ–≥–æ–≤, —Å–º–µ—â–µ–Ω–∏–µ timestamp –æ—Ç base_time)
    test_data = [
        # –ì—Ä—É–ø–ø–∞ 1: T1 (16:21) - 8 –∑–∞–ø–∏—Å–µ–π
        ("rec_00", "T1", 1.0),
        ("rec_01", "T1", 1.0),
        ("rec_02", "T1", 1.0),
        ("rec_03", "T1", 1.0),
        ("rec_04", "T1", 1.0),
        ("rec_05", "T1", 1.0),
        ("rec_06", "T1", 1.0),
        ("rec_07", "T1", 1.0),

        # –ì—Ä—É–ø–ø–∞ 2: T2 (17:00) - 5 –∑–∞–ø–∏—Å–µ–π
        # ‚ö†Ô∏è –ö–†–ò–¢–ò–ß–ù–û: rec_08 –∏ rec_09 –≤–æ–π–¥—É—Ç –≤ –ü–ï–†–í–´–ô –±–∞—Ç—á
        #              rec_10, rec_11, rec_12 –æ—Å—Ç–∞–Ω—É—Ç—Å—è –Ω–∞ –í–¢–û–†–û–ô –±–∞—Ç—á
        ("rec_08", "T2", 2.0),
        ("rec_09", "T2", 2.0),
        ("rec_10", "T2", 2.0),  # üö® –ë–£–î–ï–¢ –ü–û–¢–ï–†–Ø–ù–ê
        ("rec_11", "T2", 2.0),  # üö® –ë–£–î–ï–¢ –ü–û–¢–ï–†–Ø–ù–ê
        ("rec_12", "T2", 2.0),  # üö® –ë–£–î–ï–¢ –ü–û–¢–ï–†–Ø–ù–ê

        # –ì—Ä—É–ø–ø–∞ 3: T3 (18:00) - 5 –∑–∞–ø–∏—Å–µ–π
        ("rec_13", "T3", 3.0),
        ("rec_14", "T3", 3.0),
        ("rec_15", "T3", 3.0),
        ("rec_16", "T3", 3.0),
        ("rec_17", "T3", 3.0),

        # –ì—Ä—É–ø–ø–∞ 4: T4 (19:00) - 4 –∑–∞–ø–∏—Å–∏
        ("rec_18", "T4", 4.0),
        ("rec_19", "T4", 4.0),
        ("rec_20", "T4", 4.0),
        ("rec_21", "T4", 4.0),

        # –ì—Ä—É–ø–ø–∞ 5: T5 (20:29) - 3 –∑–∞–ø–∏—Å–∏
        ("rec_22", "T5", 5.0),
        ("rec_23", "T5", 5.0),
        ("rec_24", "T5", 5.0),
    ]

    return test_data


def print_test_data_visualization(test_data: List[Tuple[str, str, float]], base_time: float):
    """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏"""
    print("\n" + "=" * 80)
    print("–ü–û–î–ì–û–¢–û–í–õ–ï–ù–ù–´–ï –¢–ï–°–¢–û–í–´–ï –î–ê–ù–ù–´–ï")
    print("=" * 80)
    print("\n–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π:", len(test_data))
    print("\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–º –º–µ—Ç–∫–∞–º:")

    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ timestamp
    by_timestamp = {}
    for record_id, label, offset in test_data:
        ts = base_time + offset
        if ts not in by_timestamp:
            by_timestamp[ts] = []
        by_timestamp[ts].append((record_id, label))

    for ts in sorted(by_timestamp.keys()):
        records = by_timestamp[ts]
        label = records[0][1]
        ids = [r[0] for r in records]
        print(f"  {label}: {len(records)} –∑–∞–ø–∏—Å–µ–π - {', '.join(ids)}")

    print("\n–û–∂–∏–¥–∞–µ–º–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –±–∞—Ç—á–∞–º (chunk_size=10, ORDER BY id):")
    print("  –ë–∞—Ç—á 1: rec_00 –¥–æ rec_09  (10 –∑–∞–ø–∏—Å–µ–π)")
    print("          update_ts: T1(8 –∑–∞–ø–∏—Å–µ–π), T2(2 –∑–∞–ø–∏—Å–∏)")
    print("          offset –ø–æ—Å–ª–µ –±–∞—Ç—á–∞ = MAX(T1, T2) = T2")
    print()
    print("  üö® –ö–†–ò–¢–ò–ß–ù–û: –°–ª–µ–¥—É—é—â–∏–π –∑–∞–ø—É—Å–∫ WHERE update_ts > T2")
    print("     –ü–†–û–ü–£–°–¢–ò–¢: rec_10, rec_11, rec_12 (update_ts == T2)")
    print()


# ============================================================================
# PRODUCTION –ë–ê–ì –¢–ï–°–¢
# ============================================================================

def test_production_bug_offset_loses_records_with_equal_update_ts(dbconn: DBConn):
    """
    –¢–µ—Å—Ç >= –Ω–µ—Ä–∞–≤–µ–Ω—Å—Ç–≤–∞ –≤ offset —Ñ–∏–ª—å—Ç—Ä–µ (–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ production –±–∞–≥–∞).

    –ò–°–•–û–î–ù–´–ô PRODUCTION –ë–ê–ì (–¥–æ –∞—Ç–æ–º–∞—Ä–Ω–æ–≥–æ commit):
    - 82,000 –∑–∞–ø–∏—Å–µ–π –Ω–∞–∫–æ–ø–ª–µ–Ω–æ, chunk_size=1000
    - –û–±—Ä–∞–±–æ—Ç–∞–Ω —Ç–æ–ª—å–∫–æ –ü–ï–†–í–´–ô –±–∞—Ç—á (—á–∞—Å—Ç–∏—á–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞)
    - offset = MAX(update_ts) –∏–∑ –±–∞—Ç—á–∞
    - –û—Å—Ç–∞–≤—à–∏–µ—Å—è –∑–∞–ø–∏—Å–∏ —Å update_ts == offset –ü–û–¢–ï–†–Ø–ù–´ (48,915 –∑–∞–ø–∏—Å–µ–π, 60%)
    - –ü—Ä–∏—á–∏–Ω–∞: WHERE update_ts > offset (—Å—Ç—Ä–æ–≥–æ–µ >) –≤–º–µ—Å—Ç–æ >=

    –ü–û–ß–ï–ú–£ –°–¢–ê–†–´–ô –¢–ï–°–¢ –ù–ï –†–ê–ë–û–¢–ê–ï–¢:
    –° –Ω–æ–≤—ã–º –∞—Ç–æ–º–∞—Ä–Ω—ã–º commit –º–µ—Ö–∞–Ω–∏–∑–º–æ–º –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ —Å–∏–º—É–ª–∏—Ä–æ–≤–∞—Ç—å —á–∞—Å—Ç–∏—á–Ω—É—é
    –æ–±—Ä–∞–±–æ—Ç–∫—É —á–µ—Ä–µ–∑ run_idx() - offset –∫–æ–º–º–∏—Ç–∏—Ç—Å—è —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ –ø–æ–ª–Ω–æ–≥–æ run_full().

    –ù–û–í–ê–Ø –í–ï–†–°–ò–Ø –¢–ï–°–¢–ê (—Å–æ–≤–º–µ—Å—Ç–∏–º–∞ —Å –∞—Ç–æ–º–∞—Ä–Ω—ã–º commit):
    1. –ó–∞–≥—Ä—É–∂–∞–µ–º 25 –∑–∞–ø–∏—Å–µ–π —Å —Ä–∞–∑–Ω—ã–º–∏ update_ts
    2. –ü–ï–†–í–´–ô run_full() –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –í–°–ï –∑–∞–ø–∏—Å–∏, offset = MAX(update_ts)
    3. –î–æ–±–∞–≤–ª—è–µ–º –ù–û–í–´–ï –∑–∞–ø–∏—Å–∏ —Å update_ts == offset (–∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π —Å–ª—É—á–∞–π!)
    4. –í–¢–û–†–û–ô run_full() –¥–æ–ª–∂–µ–Ω –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —ç—Ç–∏ –∑–∞–ø–∏—Å–∏ (—Ç–µ—Å—Ç >= –≤–º–µ—Å—Ç–æ >)
    5. –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –ù–ï–¢ –ø–æ—Ç–µ—Ä—å –¥–∞–Ω–Ω—ã—Ö

    –ö–û–ì–î–ê –í–û–ó–ú–û–ñ–ï–ù –°–¶–ï–ù–ê–†–ò–ô "update_ts == offset –º–µ–∂–¥—É –∑–∞–ø—É—Å–∫–∞–º–∏"?
    - Clock skew –º–µ–∂–¥—É —Å–µ—Ä–≤–µ—Ä–∞–º–∏ (—Ä–∞–∑–Ω—ã–µ —Å–∏—Å—Ç–µ–º–Ω—ã–µ —á–∞—Å—ã)
    - Backfill —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Å –ø—Ä–æ—à–ª—ã–º–∏ timestamp
    - Delayed records –∏–∑ –æ—á–µ—Ä–µ–¥–∏ —Å –∑–∞–¥–µ—Ä–∂–∫–æ–π
    - –†—É—á–Ω–æ–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –∑–∞–ø–∏—Å–µ–π —Å –∫–∞—Å—Ç–æ–º–Ω—ã–º timestamp

    –°–£–¢–¨ –¢–ï–°–¢–ê:
    –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ >= —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –∏ –∑–∞–ø–∏—Å–∏ —Å update_ts == offset
    –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è, –∞ –Ω–µ —Ç–µ—Ä—è—é—Ç—Å—è (–Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç —Å—Ü–µ–Ω–∞—Ä–∏—è –≤–æ–∑–Ω–∏–∫–Ω–æ–≤–µ–Ω–∏—è).
    """
    # ========== SETUP ==========
    ds = DataStore(dbconn, create_meta_table=True)

    input_store = TableStoreDB(
        dbconn,
        "production_bug_input",
        [
            Column("id", String, primary_key=True),
            Column("value", Integer),
        ],
        create_table=True,
    )
    input_dt = ds.create_table("production_bug_input", input_store)

    output_store = TableStoreDB(
        dbconn,
        "production_bug_output",
        [
            Column("id", String, primary_key=True),
            Column("value", Integer),
        ],
        create_table=True,
    )
    output_dt = ds.create_table("production_bug_output", output_store)

    def copy_func(df):
        """–ü—Ä–æ—Å—Ç–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è (–∫–∞–∫ copy_to_online –≤ production)"""
        return df[["id", "value"]]

    step = BatchTransformStep(
        ds=ds,
        name="production_bug_copy",
        func=copy_func,
        input_dts=[ComputeInput(dt=input_dt, join_type="full")],
        output_dts=[output_dt],
        transform_keys=["id"],
        use_offset_optimization=True,
        chunk_size=10,  # –ú–∞–ª–µ–Ω—å–∫–∏–π –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∞ (–≤ production=1000)
    )

    # ========== –ü–û–î–ì–û–¢–û–í–ö–ê –ù–ê–ß–ê–õ–¨–ù–´–• –î–ê–ù–ù–´–• ==========
    base_time = time.time()
    test_data = prepare_test_data()

    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
    print_test_data_visualization(test_data, base_time)

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–∞—á–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≥—Ä—É–ø–ø–∞–º–∏ –ø–æ timestamp
    for record_id, label, offset in test_data:
        ts = base_time + offset
        input_dt.store_chunk(
            pd.DataFrame({"id": [record_id], "value": [int(offset * 100)]}),
            now=ts
        )
        time.sleep(0.001)  # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ timestamp

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    all_meta = input_dt.meta_table.get_metadata()
    print(f"\n‚úì –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {len(all_meta)}")

    # ========== –ü–ï–†–í–´–ô –ó–ê–ü–£–°–ö (–æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö –Ω–∞—á–∞–ª—å–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π) ==========
    print("\n" + "=" * 80)
    print("–ü–ï–†–í–´–ô –ó–ê–ü–£–°–ö –¢–†–ê–ù–°–§–û–†–ú–ê–¶–ò–ò (run_full)")
    print("=" * 80)

    step.run_full(ds)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º offset –ø–æ—Å–ª–µ –ø–µ—Ä–≤–æ–≥–æ –∑–∞–ø—É—Å–∫–∞
    offsets = ds.offset_table.get_offsets_for_transformation(step.get_name())
    offset_after_first = offsets["production_bug_input"]

    output_after_first = output_dt.get_data()

    print(f"\n‚úì –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞–ø–∏—Å–µ–π: {len(output_after_first)}")
    print(f"‚úì offset —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –Ω–∞: {offset_after_first:.2f}")

    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–∞–∫–∏–µ –∑–∞–ø–∏—Å–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã
    processed_ids = sorted(output_after_first["id"].tolist())
    print(f"‚úì –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ id: {', '.join(processed_ids[:5])}...{', '.join(processed_ids[-2:])}")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≤—Å–µ –Ω–∞—á–∞–ª—å–Ω—ã–µ –∑–∞–ø–∏—Å–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã
    assert len(output_after_first) == len(test_data), (
        f"–û–®–ò–ë–ö–ê: –ü–µ—Ä–≤—ã–π run_full –¥–æ–ª–∂–µ–Ω –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤—Å–µ –∑–∞–ø–∏—Å–∏. "
        f"–û–∂–∏–¥–∞–ª–æ—Å—å {len(test_data)}, –ø–æ–ª—É—á–µ–Ω–æ {len(output_after_first)}"
    )

    # ========== –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô –°–¶–ï–ù–ê–†–ò–ô: –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–ø–∏—Å–∏ —Å update_ts == offset ==========
    print("\n" + "=" * 80)
    print("–ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô –°–¶–ï–ù–ê–†–ò–ô: –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∑–∞–ø–∏—Å–µ–π —Å update_ts == offset")
    print("=" * 80)

    # –î–æ–±–∞–≤–ª—è–µ–º –ù–û–í–´–ï –∑–∞–ø–∏—Å–∏ —Å timestamp –†–ê–í–ù–´–ú offset
    # –≠—Ç–æ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç production –±–∞–≥: –∑–∞–ø–∏—Å–∏ —Å update_ts == offset –¥–æ–ª–∂–Ω—ã –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å—Å—è!
    critical_timestamp = offset_after_first
    critical_records = [
        ("rec_critical_01", 999),
        ("rec_critical_02", 998),
        ("rec_critical_03", 997),
    ]

    print(f"\n–î–æ–±–∞–≤–ª—è–µ–º {len(critical_records)} –∑–∞–ø–∏—Å–µ–π —Å update_ts == {critical_timestamp:.2f}")
    for record_id, value in critical_records:
        input_dt.store_chunk(
            pd.DataFrame({"id": [record_id], "value": [value]}),
            now=critical_timestamp
        )
        time.sleep(0.001)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –∑–∞–ø–∏—Å–∏ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –∏–º–µ—é—Ç update_ts == offset
    critical_meta = input_dt.meta_table.get_metadata(
        pd.DataFrame({"id": [rec[0] for rec in critical_records]})
    )
    for idx, row in critical_meta.iterrows():
        assert abs(row["update_ts"] - critical_timestamp) < 0.01, (
            f"–û–®–ò–ë–ö–ê –í –¢–ï–°–¢–ï: –ó–∞–ø–∏—Å—å {row['id']} –¥–æ–ª–∂–Ω–∞ –∏–º–µ—Ç—å update_ts == offset"
        )
        print(f"  {row['id']}: update_ts={row['update_ts']:.2f} == offset={critical_timestamp:.2f}")

    # ========== –í–¢–û–†–û–ô –ó–ê–ü–£–°–ö (—Ç–µ—Å—Ç–∏—Ä—É–µ–º >= –≤–º–µ—Å—Ç–æ >) ==========
    print("\n" + "=" * 80)
    print("–í–¢–û–†–û–ô –ó–ê–ü–£–°–ö –¢–†–ê–ù–°–§–û–†–ú–ê–¶–ò–ò (–ø—Ä–æ–≤–µ—Ä–∫–∞ >= –≤–º–µ—Å—Ç–æ >)")
    print("=" * 80)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–∫–æ–ª—å–∫–æ –∑–∞–ø–∏—Å–µ–π –±—É–¥–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ
    changed_count = step.get_changed_idx_count(ds)
    print(f"–ó–∞–ø–∏—Å–µ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {changed_count}")

    if changed_count == 0:
        pytest.fail(
            f"\nüö® –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô –ë–ê–ì –í OFFSET OPTIMIZATION!\n"
            f"{'=' * 50}\n"
            f"–î–æ–±–∞–≤–ª–µ–Ω–æ {len(critical_records)} –ù–û–í–´–• –∑–∞–ø–∏—Å–µ–π —Å update_ts == offset={critical_timestamp:.2f}\n"
            f"–ù–æ get_changed_idx_count –≤–µ—Ä–Ω—É–ª 0 - –∑–∞–ø–∏—Å–∏ –ù–ï –í–ò–î–ù–´ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏!\n\n"
            f"–ú–ï–•–ê–ù–ò–ó–ú –ë–ê–ì–ê:\n"
            f"WHERE update_ts > offset (—Å—Ç—Ä–æ–≥–æ–µ –Ω–µ—Ä–∞–≤–µ–Ω—Å—Ç–≤–æ!) –ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç –∑–∞–ø–∏—Å–∏ —Å update_ts == offset\n"
            f"–î–æ–ª–∂–Ω–æ –±—ã—Ç—å: WHERE update_ts >= offset\n\n"
            f"–í PRODUCTION: –≠—Ç–æ—Ç –±–∞–≥ –ø—Ä–∏–≤–µ–ª –∫ –ø–æ—Ç–µ—Ä–µ 48,915 –∏–∑ 82,000 –∑–∞–ø–∏—Å–µ–π (60%)\n"
            f"{'=' * 50}"
        )

    # NOTE: changed_count –º–æ–∂–µ—Ç –±—ã—Ç—å > len(critical_records) –ø–æ—Ç–æ–º—É —á—Ç–æ >= –≤–∫–ª—é—á–∞–µ—Ç
    # —Å—Ç–∞—Ä—ã–µ –∑–∞–ø–∏—Å–∏ —Å update_ts == offset. –°–∏—Å—Ç–µ–º–∞ –æ—Ç—Ñ–∏–ª—å—Ç—Ä—É–µ—Ç –∏—Ö –ø–æ process_ts.
    # –ì–ª–∞–≤–Ω–æ–µ - —á—Ç–æ–±—ã –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–ø–∏—Å–∏ –±—ã–ª–∏ –≤–∏–¥–Ω—ã –∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã!
    print(f"  (–º–æ–∂–µ—Ç –≤–∫–ª—é—á–∞—Ç—å —Å—Ç–∞—Ä—ã–µ –∑–∞–ø–∏—Å–∏ —Å update_ts == offset, –æ–Ω–∏ –±—É–¥—É—Ç –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω—ã –ø–æ process_ts)")

    # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É
    step.run_full(ds)

    # ========== –ü–†–û–í–ï–†–ö–ê –†–ï–ó–£–õ–¨–¢–ê–¢–ê ==========
    print("\n" + "=" * 80)
    print("–ü–†–û–í–ï–†–ö–ê –†–ï–ó–£–õ–¨–¢–ê–¢–ê")
    print("=" * 80)

    final_output = output_dt.get_data()
    final_processed_ids = set(final_output["id"].tolist())

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≤—Å–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–ø–∏—Å–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã
    all_critical_processed = all(rec[0] in final_processed_ids for rec in critical_records)

    print(f"\n–§–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:")
    print(f"  –ù–∞—á–∞–ª—å–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π:      {len(test_data)}")
    print(f"  –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –∑–∞–ø–∏—Å–µ–π:    {len(critical_records)}")
    print(f"  –í–°–ï–ì–û –æ–∂–∏–¥–∞–µ—Ç—Å—è:        {len(test_data) + len(critical_records)}")
    print(f"  –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –≤ output:    {len(final_output)}")

    if not all_critical_processed:
        lost_critical = [rec[0] for rec in critical_records if rec[0] not in final_processed_ids]
        print(f"\nüö® –ü–û–¢–ï–†–Ø–ù–´ –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï –ó–ê–ü–ò–°–ò: {lost_critical}")

        pytest.fail(
            f"\nüö® –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô –ë–ê–ì –í OFFSET OPTIMIZATION!\n"
            f"{'=' * 50}\n"
            f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–ø–∏—Å–∏ —Å update_ts == offset –ù–ï –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã!\n"
            f"–ü–æ—Ç–µ—Ä—è–Ω–æ: {len(lost_critical)} –∏–∑ {len(critical_records)}\n"
            f"–ü–æ—Ç–µ—Ä—è–Ω–Ω—ã–µ id: {lost_critical}\n\n"
            f"–ú–ï–•–ê–ù–ò–ó–ú –ë–ê–ì–ê:\n"
            f"WHERE update_ts > offset (—Å—Ç—Ä–æ–≥–æ–µ >) –≤–º–µ—Å—Ç–æ >=\n"
            f"–ó–∞–ø–∏—Å–∏ —Å update_ts == offset –ø—Ä–æ–ø—É—Å–∫–∞—é—Ç—Å—è!\n\n"
            f"–í PRODUCTION: 82,000 –∑–∞–ø–∏—Å–µ–π, –ø–æ—Ç–µ—Ä—è–Ω–æ 48,915 (60%)\n"
            f"{'=' * 50}"
        )

    # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –≤—Å–µ –∑–∞–ø–∏—Å–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã
    expected_total = len(test_data) + len(critical_records)
    assert len(final_output) == expected_total, (
        f"–û–∂–∏–¥–∞–ª–æ—Å—å {expected_total} –∑–∞–ø–∏—Å–µ–π, –ø–æ–ª—É—á–µ–Ω–æ {len(final_output)}"
    )

    print(f"\n‚úÖ –í—Å–µ –∑–∞–ø–∏—Å–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ!")
    print(f"‚úÖ –ó–∞–ø–∏—Å–∏ —Å update_ts == offset –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã (>= —Ä–∞–±–æ—Ç–∞–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ)")


if __name__ == "__main__":
    # –î–ª—è —Ä—É—á–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ –∏ –æ—Ç–ª–∞–¥–∫–∏
    from datapipe.store.database import DBConn
    from sqlalchemy import create_engine, text

    DBCONNSTR = "postgresql://postgres:password@localhost:5432/postgres"
    DB_TEST_SCHEMA = "test_production_bug"

    eng = create_engine(DBCONNSTR)
    try:
        with eng.begin() as conn:
            conn.execute(text(f"DROP SCHEMA {DB_TEST_SCHEMA} CASCADE"))
    except Exception:
        pass

    with eng.begin() as conn:
        conn.execute(text(f"CREATE SCHEMA {DB_TEST_SCHEMA}"))

    test_dbconn = DBConn(DBCONNSTR, DB_TEST_SCHEMA)

    print("–ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∞ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è production –±–∞–≥–∞...")
    test_production_bug_offset_loses_records_with_equal_update_ts(test_dbconn)
