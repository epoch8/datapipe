"""
Ð¢ÐµÑÑ‚ Ð´Ð»Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ¸ Ñ‡Ñ‚Ð¾ offset'Ñ‹ ÑÐ¾Ð·Ð´Ð°ÑŽÑ‚ÑÑ Ð´Ð»Ñ JoinSpec Ñ‚Ð°Ð±Ð»Ð¸Ñ† (Ñ join_keys).

Ð’Ð¾ÑÐ¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ Ð±Ð°Ð³ Ð³Ð´Ðµ offset ÑÐ¾Ð·Ð´Ð°Ð²Ð°Ð»ÑÑ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð´Ð»Ñ Ð³Ð»Ð°Ð²Ð½Ð¾Ð¹ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹ (posts),
Ð½Ð¾ Ð½Ðµ Ð´Ð»Ñ ÑÐ¿Ñ€Ð°Ð²Ð¾Ñ‡Ð½Ð¾Ð¹ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹ (profiles) Ñ join_keys.
"""

import time

import pandas as pd
from sqlalchemy import Column, Integer, String

from datapipe.compute import ComputeInput
from datapipe.datatable import DataStore
from datapipe.step.batch_transform import BatchTransformStep
from datapipe.store.database import DBConn, TableStoreDB


def test_offset_created_for_joinspec_tables(dbconn: DBConn):
    """
    ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÑ‚ Ñ‡Ñ‚Ð¾ offset ÑÐ¾Ð·Ð´Ð°ÐµÑ‚ÑÑ Ð´Ð»Ñ Ñ‚Ð°Ð±Ð»Ð¸Ñ† Ñ join_keys (JoinSpec).

    Ð¡Ñ†ÐµÐ½Ð°Ñ€Ð¸Ð¹:
    1. Ð¡Ð¾Ð·Ð´Ð°Ñ‘Ð¼ posts Ð¸ profiles (profiles Ñ join_keys={'user_id': 'id'})
    2. Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ñ‚Ñ€Ð°Ð½ÑÑ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ñ offset optimization
    3. ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ñ‡Ñ‚Ð¾ offset ÑÐ¾Ð·Ð´Ð°Ð½ Ð”Ð›Ð¯ ÐžÐ‘Ð•Ð˜Ð¥ Ñ‚Ð°Ð±Ð»Ð¸Ñ†: posts Ð˜ profiles
    """
    ds = DataStore(dbconn, create_meta_table=True)

    # 1. Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ posts Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñƒ (Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ String Ð´Ð»Ñ id Ñ‡Ñ‚Ð¾Ð±Ñ‹ ÑÐ¾Ð²Ð¿Ð°Ð´Ð°Ñ‚ÑŒ Ñ Ð¼ÐµÑ‚Ð°-Ñ‚Ð°Ð±Ð»Ð¸Ñ†ÐµÐ¹)
    posts_store = TableStoreDB(
        dbconn,
        "posts",
        [
            Column("id", String, primary_key=True),
            Column("user_id", String),
            Column("content", String),
        ],
        create_table=True,
    )
    posts = ds.create_table("posts", posts_store)

    # 2. Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ profiles Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñƒ (ÑÐ¿Ñ€Ð°Ð²Ð¾Ñ‡Ð½Ð¸Ðº)
    profiles_store = TableStoreDB(
        dbconn,
        "profiles",
        [Column("id", String, primary_key=True), Column("username", String)],
        create_table=True,
    )
    profiles = ds.create_table("profiles", profiles_store)

    # 3. Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ output Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñƒ (id - primary key, Ð¾ÑÑ‚Ð°Ð»ÑŒÐ½Ð¾Ðµ - Ð´Ð°Ð½Ð½Ñ‹Ðµ)
    output_store = TableStoreDB(
        dbconn,
        "posts_with_username",
        [
            Column("id", String, primary_key=True),
            Column("user_id", String),  # ÐžÐ±Ñ‹Ñ‡Ð½Ð°Ñ ÐºÐ¾Ð»Ð¾Ð½ÐºÐ°, Ð½Ðµ primary key
            Column("content", String),
            Column("username", String),
        ],
        create_table=True,
    )
    output_dt = ds.create_table("posts_with_username", output_store)

    # 4. Ð”Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ Ð´Ð°Ð½Ð½Ñ‹Ðµ
    process_ts = time.time()

    # 3 Ð¿Ð¾ÑÑ‚Ð° Ð¾Ñ‚ 2 Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÐµÐ¹
    posts_df = pd.DataFrame([
        {"id": "1", "user_id": "1", "content": "Post 1"},
        {"id": "2", "user_id": "1", "content": "Post 2"},
        {"id": "3", "user_id": "2", "content": "Post 3"},
    ])
    posts.store_chunk(posts_df, now=process_ts)

    # 2 Ð¿Ñ€Ð¾Ñ„Ð¸Ð»Ñ
    profiles_df = pd.DataFrame([
        {"id": "1", "username": "alice"},
        {"id": "2", "username": "bob"},
    ])
    profiles.store_chunk(profiles_df, now=process_ts)

    # 5. Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ Ñ‚Ñ€Ð°Ð½ÑÑ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ñ join_keys
    def transform_func(posts_df, profiles_df):
        # JOIN posts + profiles
        result = posts_df.merge(profiles_df, left_on="user_id", right_on="id", suffixes=("", "_profile"))
        return result[["id", "user_id", "content", "username"]]

    step = BatchTransformStep(
        ds=ds,
        name="test_transform",
        func=transform_func,
        input_dts=[
            ComputeInput(dt=posts, join_type="full"),  # Ð“Ð»Ð°Ð²Ð½Ð°Ñ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ð°
            ComputeInput(dt=profiles, join_type="inner", join_keys={"user_id": "id"}),  # JoinSpec Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ð°
        ],
        output_dts=[output_dt],
        transform_keys=["id"],  # Primary key Ð¿ÐµÑ€Ð²Ð¾Ð¹ Ñ‚Ð°Ð±Ð»Ð¸Ñ†Ñ‹ (posts)
        use_offset_optimization=True,  # Ð’ÐÐ–ÐÐž: Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ offset optimization
    )

    # 6. Ð—Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚ÑŒ Ñ‚Ñ€Ð°Ð½ÑÑ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ
    print("\nðŸš€ Running initial transformation...")
    step.run_full(ds)

    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ñ‚Ñ€Ð°Ð½ÑÑ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸
    output_data = output_dt.get_data()
    print(f"âœ… Output rows created: {len(output_data)}")
    print(f"Output data:\n{output_data}")

    # 7. ÐŸÑ€Ð¾Ð²ÐµÑ€Ð¸Ñ‚ÑŒ Ñ‡Ñ‚Ð¾ offset'Ñ‹ ÑÐ¾Ð·Ð´Ð°Ð½Ñ‹ Ð´Ð»Ñ ÐžÐ‘Ð•Ð˜Ð¥ Ñ‚Ð°Ð±Ð»Ð¸Ñ†
    print("\nðŸ” Checking offsets...")
    # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ step.get_name() Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð¸Ð¼Ñ Ñ Ñ…ÑÑˆÐµÐ¼
    transform_name = step.get_name()
    print(f"ðŸ”‘ Transform name with hash: {transform_name}")
    offsets = ds.offset_table.get_offsets_for_transformation(transform_name)

    print(f"ðŸ“Š Offsets created: {offsets}")

    # ÐšÐ Ð˜Ð¢Ð˜Ð§Ð•Ð¡ÐšÐ˜ Ð’ÐÐ–ÐÐž: offset Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð±Ñ‹Ñ‚ÑŒ Ð´Ð»Ñ posts Ð˜ Ð´Ð»Ñ profiles!
    assert "posts" in offsets, "Offset for 'posts' table not found!"
    assert "profiles" in offsets, "Offset for 'profiles' table not found! (Ð‘ÐÐ“!)"

    # ÐžÐ±Ð° offset'Ð° Ð´Ð¾Ð»Ð¶Ð½Ñ‹ Ð±Ñ‹Ñ‚ÑŒ >= process_ts
    assert offsets["posts"] >= process_ts, f"posts offset {offsets['posts']} < process_ts {process_ts}"
    assert offsets["profiles"] >= process_ts, f"profiles offset {offsets['profiles']} < process_ts {process_ts}"

    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ñ‡Ñ‚Ð¾ Ð±Ñ‹Ð»Ð¸ ÑÐ¾Ð·Ð´Ð°Ð½Ñ‹ 3 Ð·Ð°Ð¿Ð¸ÑÐ¸ Ð² output
    output_data = output_dt.get_data()
    assert len(output_data) == 3, f"Expected 3 output rows, got {len(output_data)}"

    # 8. Ð”Ð¾Ð±Ð°Ð²Ð¸Ð¼ Ð½Ð¾Ð²Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¸ Ð¿Ñ€Ð¾Ð²ÐµÑ€Ð¸Ð¼ Ð¸Ð½ÐºÑ€ÐµÐ¼ÐµÐ½Ñ‚Ð°Ð»ÑŒÐ½ÑƒÑŽ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÑƒ
    time.sleep(0.01)  # ÐÐµÐ±Ð¾Ð»ÑŒÑˆÐ°Ñ Ð·Ð°Ð´ÐµÑ€Ð¶ÐºÐ° Ð´Ð»Ñ Ñ€Ð°Ð·Ð»Ð¸Ñ‡ÐµÐ½Ð¸Ñ timestamp'Ð¾Ð²
    process_ts2 = time.time()

    # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ 1 Ð½Ð¾Ð²Ñ‹Ð¹ Ð¿Ð¾ÑÑ‚
    new_posts_df = pd.DataFrame([
        {"id": "4", "user_id": "1", "content": "New Post 4"},
    ])
    posts.store_chunk(new_posts_df, now=process_ts2)

    # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ 1 Ð½Ð¾Ð²Ñ‹Ð¹ Ð¿Ñ€Ð¾Ñ„Ð¸Ð»ÑŒ
    new_profiles_df = pd.DataFrame([
        {"id": "3", "username": "charlie"},
    ])
    profiles.store_chunk(new_profiles_df, now=process_ts2)

    # 9. Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð¸Ð½ÐºÑ€ÐµÐ¼ÐµÐ½Ñ‚Ð°Ð»ÑŒÐ½ÑƒÑŽ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÑƒ
    step.run_full(ds)

    # 10. ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ñ‡Ñ‚Ð¾ offset'Ñ‹ Ð¾Ð±Ð½Ð¾Ð²Ð¸Ð»Ð¸ÑÑŒ
    new_offsets = ds.offset_table.get_offsets_for_transformation(transform_name)

    print(f"\nðŸ“Š New offsets after incremental run: {new_offsets}")

    # ÐžÐ±Ð° offset'Ð° Ð´Ð¾Ð»Ð¶Ð½Ñ‹ Ð¾Ð±Ð½Ð¾Ð²Ð¸Ñ‚ÑŒÑÑ Ð´Ð¾ process_ts2
    assert new_offsets["posts"] >= process_ts2, f"posts offset not updated: {new_offsets['posts']} < {process_ts2}"
    assert new_offsets["profiles"] >= process_ts2, f"profiles offset not updated: {new_offsets['profiles']} < {process_ts2}"

    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ñ‡Ñ‚Ð¾ Ñ‚ÐµÐ¿ÐµÑ€ÑŒ 4 Ð·Ð°Ð¿Ð¸ÑÐ¸ Ð² output (3 ÑÑ‚Ð°Ñ€Ñ‹Ñ… + 1 Ð½Ð¾Ð²Ñ‹Ð¹ Ð¿Ð¾ÑÑ‚)
    output_data = output_dt.get_data()
    assert len(output_data) == 4, f"Expected 4 output rows, got {len(output_data)}"

    print("\nâœ… SUCCESS: Offsets created and updated for both posts AND profiles (including JoinSpec table)!")
